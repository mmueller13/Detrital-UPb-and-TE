{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7664583b",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Detrital-Common-Pb-Corrections</div>\n",
    "## <div align=\"center\">Python code for common Pb corrections of detrital U-Pb data</div>\n",
    "#### <div align=\"center\">Megan Mueller</div>\n",
    "##### <div align=\"center\">Please cite the accompanying article published in Geochronology:</div>\n",
    "<div align=\"center\">Mueller et al., 2024, https://doi.org/10.5194/gchron-6-265-2024 </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335450f5",
   "metadata": {},
   "source": [
    "# Overview \n",
    "This notebook performs 207Pb and 208Pb corrections for detrital U-Pb data. \n",
    "\n",
    "### Initial Conditions\n",
    "The code was written using file input as .xlsx file from iolite 4 output, described below. The code can be modified for other file input structures. \n",
    "\n",
    "### Organization\n",
    "The notebook is divided into the following sections: \n",
    "1. [Data import and initial code](#Section1)\n",
    "2. [208Pb correction](#Section2)\n",
    "3. [207Pb correction](#Section3)\n",
    "4. [Export results](#Section4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0a5b5",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "# 1. Import Data and Set-Up\n",
    "\n",
    "\n",
    "## 1.1 Install Python Packages and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94057f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Python packages\n",
    "# Run to see if installed, if not, will install\n",
    "# Only need to install once\n",
    "\n",
    "import importlib\n",
    "from subprocess import run\n",
    "\n",
    "def install_if_not_installed(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"Package {package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing package: {package_name}\")\n",
    "        run(['pip', 'install', package_name], check=True)\n",
    "        print(f\"Installed package: {package_name}\")\n",
    "\n",
    "install_if_not_installed(\"pandas\") # Install pandas\n",
    "install_if_not_installed(\"numpy\") # Install numpy\n",
    "install_if_not_installed(\"matplotlib\") # Install matplotlib\n",
    "install_if_not_installed(\"tabulate\") # Install tabulate\n",
    "install_if_not_installed(\"sympy\") # Install sympy\n",
    "install_if_not_installed(\"easygui\") # Install easygui\n",
    "install_if_not_installed(\"cmcrameri\") # Install cmcrameri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from sympy import symbols, Eq, solve, exp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import root\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import easygui\n",
    "from cmcrameri import cm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167548b",
   "metadata": {},
   "source": [
    "## 1.2 Input File Organization (Data Needed to Run)\n",
    "Run this section of code to load Excel spreadsheet with U-Pb data. Edit the code to specify the orrect file path, file name, and Excel sheet tab.\n",
    "The following sections of code use the following data which must be present in the input file: \n",
    "- Grain ID name\n",
    "- Counts per second: 206, 207, 208\n",
    "- U-Pb ratios and uncertainties (1s or 2s absolute): 206/238, 238/206 and 207/206\n",
    "- Error correlation (rho 207Pb/206Pb v 238U/206Pb)\n",
    "- U/Th ratio\n",
    "- U concentration (ppm)\n",
    "\n",
    "\n",
    "The example dataset is a table of U-Pb and trace element data for all detrital rutile unknowns from Mueller et al.:\n",
    "\n",
    "ExampleDataset-DetritalCommonPbCorrections-Muelleretal_Unknowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Excel file with data into DataFrame\n",
    "\n",
    "# Specify the folder and file name\n",
    "folder_path = r'C:\\Users\\megan\\Dropbox\\CommonPbPython\\Example-data'  # Update this with the actual path\n",
    "file_name = 'ExampleDataset-DetritalCommonPbCorrections-Muelleretal_Unknowns.xlsx'  # Update this with the actual file name\n",
    "sheet_name = 'AllUnknowns'  # Update this with the actual sheet name\n",
    "\n",
    "# Combine folder path and file name using os.path.join\n",
    "excel_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Load a specific sheet into a DataFrame\n",
    "df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(10) # display first 10 rows of DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ca35e",
   "metadata": {},
   "source": [
    "<a id='DefineVariables'></a>\n",
    "## 1.3 Define Variables\n",
    "The following cell defines the input variables used in all subsequent calculations. Note that the column headings are displayed in the output of the above cell. Change the below code if the columns are named differently. Code here uses default column headings from iolite 4 export.\n",
    "\n",
    "Note that all calculations are assuming the input uncertainties are 2 sigma absolute. The cell below prompts the user to specify whether inputs are 1s absolute or 2s absolute; if 1s absolute then the inputs are converted to 2s absolute. The below code expects uncertainty values as absolute not percent.\n",
    "\n",
    "*Warning: Code prompts user (bottom), will not continue without an input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this section to add/remove columns to include as variables as needed\n",
    "# Everything here will be used in subsequent code\n",
    "# Edit if column names are different than below. See column names in above cell output (or, run df.head(15) )\n",
    "\n",
    "# Define variables by column headers\n",
    "data_dict = df.to_dict(orient='series')\n",
    "\n",
    "# Initial measured and calculated values (required)\n",
    "GrainID = df['Grain_ID']\n",
    "i206CPS = df['Pb206_CPS_mean']\n",
    "i207CPS = df['Pb207_CPS_mean']\n",
    "i208CPS = df['Pb208_CPS_mean']\n",
    "iUTh = df['Raw U/Th_mean']\n",
    "i386 = df['Final U238/Pb206_mean']\n",
    "i386err = df['Final U238/Pb206_2SE(prop)'] # 2s absolute\n",
    "i638 = df['Final Pb206/U238_mean']\n",
    "i638err = df['Final Pb206/U238_2SE(prop)'] # 2s absolute\n",
    "t638 = df['Final Pb206/U238 age_mean']\n",
    "t638err = df['Final Pb206/U238 age_2SE(prop)'] # 2s absolute\n",
    "i76 = df['Final Pb207/Pb206_mean']\n",
    "i76err = df['Final Pb207/Pb206_2SE(prop)'] # 2s absolute\n",
    "t76 = df['Final Pb207/Pb206 age_mean']\n",
    "t76err = df['Final Pb207/Pb206 age_2SE(prop)'] # 2s absolute\n",
    "rho = df['rho 207Pb/206Pb v 238U/206Pb']\n",
    "U = df['Approx_U_PPM_mean']\n",
    "\n",
    "user_input = input("Are input file uncertainties 1-sigma absolute or 2-sigma absolute? \nType '1' or '2' (not 'one' or 'two') \nIf 2, no calculations will be performed \nIf 1, input uncertainties will be multiplied by 2\n")
    "if user_input.lower() == '2':\n",
    "    print(\"\\033[1mInput uncertainties are 2s\\033[0m\")\n",
    "elif user_input == '1':\n",
    "    # Will run the following code if input uncertainties are 1s (abs) and not 2s (abs)\n",
    "    i386err = df['Final U238/Pb206_2SE(prop)'] * 2 # 2s absolute\n",
    "    i638err = df['Final Pb206/U238_2SE(prop)'] * 2 # 2s absolute\n",
    "    t638err = df['Final Pb206/U238 age_2SE(prop)'] * 2 # 2s absolute\n",
    "    i76err = df['Final Pb207/Pb206_2SE(prop)'] * 2 # 2s absolute\n",
    "    t76err = df['Final Pb207/Pb206 age_2SE(prop)'] * 2 # 2s absolute\n",
    "    print('\\033[1mReminder:\\033[0m Input uncertainties are 1s and were multiplied by 2. Subsequent calculations and outputs will be at 2s level')\n",
    "else:\n",
    "    print(\"\\033[1mOpe. Invalid input. Please enter '1' or '2'.\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial calculations for Pb corrections\n",
    "\n",
    "# Define constants\n",
    "instUTh = 1; # instrument-specific U/Th, should be =1 and already corrected during data reduction\n",
    "rat85 = 137.88; # 238U/235U ratio. 137.88 from Steiger and Jäger (1977). 137.818 from Hiess et al. (2012). \n",
    "rat58 = 0.007252683; # 1/137.88 constant 235/238 U ratio\n",
    "lambda238 = 1.55125E-10; # U238 decay constant from Faure (1986)\n",
    "lambda235 = 9.8485E-10; # U235 decay constant from Faure (1986)\n",
    "lambda232 = 4.9475E-11; # 232Th decay constant\n",
    "\n",
    "\n",
    "# Calculate Th/U ratio\n",
    "# Avoid division by zero and handle invalid values\n",
    "instThUc = np.divide(1, iUTh, out=np.zeros_like(iUTh), where=iUTh != 0) * instUTh # Th/U ratio\n",
    "\n",
    "# Ratios calculated from CPS:\n",
    "meas68 = np.divide(i206CPS, i208CPS, out=np.zeros_like(i206CPS), where=i208CPS != 0)\n",
    "meas67 = np.divide(i206CPS, i207CPS, out=np.zeros_like(i206CPS), where=i207CPS != 0)\n",
    "meas76 = np.divide(i207CPS, i206CPS, out=np.zeros_like(i207CPS), where=i206CPS != 0)\n",
    "\n",
    "# Create the R array with all ratios for each grain\n",
    "R = np.zeros((len(GrainID), 5))\n",
    "R = np.column_stack((meas68, 1/meas68, instThUc, meas67, meas76))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec2c3c",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "# 2. 208Pb Correction\n",
    "Iteratively calculate 208Pb corrected age\n",
    "\n",
    "The 208Pb correction method determines the common Pb component using the 232Th-208Pb decay scheme and assumes U-Th-Pb concordance, Th/U remained undistrubed, and no Pb loss. Because Pb loss is not considered, all corrected dates are (possibly) minimum ages.\n",
    "\n",
    "The 208Pb correction iterates on initial age and Stacey and Kramers (1975) terrestrial Pb evolution model. The measured isotopes are the iolite baseline-corrected CPS values (defined in [Section 1](#DefineVariables)). The initial age is the uncorrected date, which is then replaced by the result of subsequent iterations. For the 2 stage terrestrial Pb evolution model of Stacey and Kramers (1975, EPSL), 3700 Ma is the boundary between the first and second stages. If the initial date is > 4570 Ma, it is set to 4570 Ma.\n",
    "\n",
    "The method here directly follows what is outlined in published papers: Williams (1997), Chew et al. (2011), McLean et al. (2011), Odlum et al. (2019), and Vermeesch (2020). The equations below benefitted from inital discussion with Margo Odlum and the UTChron group.\n",
    "\n",
    "## 2.1 Define 208Pb Correction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for 208 Pb corrections\n",
    "# Only need to run this once per session\n",
    "\n",
    "# 208 Pb Correction\n",
    "def iterative_208Pb(initial_age, i638_values, i638err_values):\n",
    "    result_array = np.zeros((len(initial_age), 8))\n",
    "\n",
    "    # Iterative section for 208Pb Correction\n",
    "    for i in range(len(initial_age)):\n",
    "        # Calculate initial common Pb section\n",
    "        # 1st stage Pb evolution from Stacey & Kramers 1975 EPSL (Table 8)\n",
    "        if (initial_age[i] != 0) & (~np.isnan(initial_age[i])): # Check for NaN or zero values in initial_age\n",
    "            if initial_age[i] > 3700:\n",
    "                a64 = 7.19 * (np.exp(lambda238 * 4.570E9) - np.exp(lambda238 * initial_age[i] * 1000000)) + 9.307\n",
    "                a84 = 33.21 * (np.exp(lambda232 * 4.570E9) - np.exp(lambda232 * initial_age[i] * 1000000)) + 29.487\n",
    "                a86 = a84 / a64 # 208/206 common\n",
    "            else:\n",
    "                # 2nd stage Pb evolution from Stacey & Kramers 1975 EPSL (Eqns 5-6; Table 8); see also McLean et al 2011 G3 (Eqns A28-A30); and Vermeesch 2020 Geochron (Eqns 25-26)\n",
    "                a64 = 9.74 * (np.exp((lambda238 * 3.7E9)) - np.exp((lambda238 * initial_age[i] * 1000000))) + 11.152 # 206/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "                a84 = 36.84 * (np.exp((lambda232 * 3.7E9)) - np.exp((lambda232 * initial_age[i] * 1000000))) + 31.23 # 208/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "                a86 = a84 / a64 # 208/206 common\n",
    "        else:\n",
    "            result_array[i, :] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            pass\n",
    "\n",
    "        # 208 Pb correction\n",
    "        if (initial_age[i] != 0) & (~np.isnan(initial_age[i])): # Check for zero values in i638[i]\n",
    "            # 208 Pb correction\n",
    "            # calculate expected radiogenic Pb ratios: 208Pb* / 206Pb* = (Th/U) [(eλ232 t* -1) / (eλ238 t* -1)]\n",
    "            c = (np.exp(lambda232 * (initial_age[i] * 1000000))) - 1 # 208Pb produced from initial age estimate\n",
    "            d = (np.exp(lambda238 * (initial_age[i] * 1000000))) - 1 # 206Pb produced from initial age estimate\n",
    "            e = instThUc[i] # recall corrected ThU value, also stored in R[i, 2]\n",
    "            c86Pb = e * (c / d) # expected radiogenic Pb 208Pb* / 206Pb*\n",
    "\n",
    "            # calculate f206, fraction of common Pb\n",
    "            g = R[i, 1] # recall measured 208/206 Pb ratio calculated from CPS\n",
    "            f206 = (g - c86Pb) / (a86 - c86Pb) # f206 = (meas. - expected)/(common - expected)\n",
    "            Rad638 = (1 - f206) * i638[i] # Radiogenic component, 206*/238 ratio \n",
    "            \n",
    "            if (Rad638 + 1) > 0:\n",
    "                # solve age equation with corrected radiogenic 206*/238 ratio to get the corrected age: t = ln ( 206/238 + 1 ) / λ238\n",
    "                AgeTot206 = ((np.log(i638[i] + 1)) / lambda238) / 1000000 # age with no correction, total 206\n",
    "                Age208c = ((np.log(Rad638 + 1)) / lambda238) / 1000000 ## *** Corrected 208 age *** \n",
    "                AgeDiffCor = Age208c - AgeTot206  # difference in ages\n",
    "\n",
    "                # calculate 2SE abs error of 208corrected age using initial % error\n",
    "                p = i638[i] # recall initial Final 206/238 ratio\n",
    "                q = i638err[i] #recall initial Final 206/238 uncertainty 2SE abs\n",
    "                cAge208cErr = Age208c / 100 * (q / p * 100) # calculate 2SE abs error of corrected age using initial % uncertainty\n",
    "\n",
    "                # Store results in the array\n",
    "                result_array[i, :] = [a86, c86Pb, f206, Rad638, AgeTot206, Age208c, cAge208cErr, AgeDiffCor]\n",
    "            \n",
    "            else:\n",
    "                result_array[i, :] = [a86, c86Pb, f206, Rad638, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "        else:\n",
    "            result_array[i, :] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            pass\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e2006",
   "metadata": {},
   "source": [
    "## 2.2 Perform Iterative 208Pb Correction\n",
    "<a id='208Manual'></a>\n",
    "### 2.2.1 Iterative 208Pb Correction - the number of iterations set manually\n",
    "The cell below runs the 208Pb correction. Define the desired number of iterations below. At least 5-10 is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 208Pb Correction \n",
    "\n",
    "# Define number of iterations\n",
    "num_iterations = 5\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dfs208_list = []\n",
    "\n",
    "# Initial date estimate\n",
    "date_estimate = t638 # iteration 1 uses uncorrected date, subsequent iterations use date calculated in previous iteration\n",
    "date_estimate = np.where(date_estimate > 4570, 4570, date_estimate)\n",
    "\n",
    "# Perform iterations\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    # Perform 208Pb correction for the current iteration\n",
    "    current_iteration_results = iterative_208Pb(date_estimate, i638, i638err)\n",
    "    \n",
    "    # Create a DataFrame for the current iteration results\n",
    "    df_iteration = pd.DataFrame(\n",
    "        current_iteration_results,\n",
    "        columns=[f\"208It{iteration}_208/206c\", f\"208It{iteration}_208/206*\",\n",
    "                 f\"208It{iteration}_f206\", f\"208It{iteration}_206*/238\",\n",
    "                 f\"208It{iteration}_DateTot206\", f\"208It{iteration}_Date208c\",\n",
    "                 f\"208It{iteration}_Date208cErr\", f\"208It{iteration}_AgeDiffCorr\"]\n",
    "    )\n",
    "    \n",
    "    # Print information about the current iteration\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {iteration} Complete\\033[0m')\n",
    "    print('Date of grain in last row (Ma):', current_iteration_results[-1, 5])\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs208_list.append(df_iteration)\n",
    "    \n",
    "    # Update the date_estimate for the next iteration\n",
    "    date_estimate = current_iteration_results[:, 5]\n",
    "\n",
    "# Display the DataFrames\n",
    "print('\\n\\n *Preview of results from every iteration:* \\n')\n",
    "for i, result208_df in enumerate(dfs208_list, start=1):\n",
    "    print(f'\\n\\n\\033[1m207Pb Correction - Iteration {i} Results DataFrame:\\033[0m')\n",
    "    print('\\ncolumns: 1- 208/206 common, 2- 208/206* radiogenic, 3- Fraction common Pb (f206), 4- 206*/238 ratio, 5- Total 206 Date (Ma), 6- 208Pb-corrected date (Ma), 7- 208Pb-corrected date uncertainty (2s abs), 8- Difference in 208Pb corr from total206 dates (Ma) \\n\\n')\n",
    "    print(result208_df.to_string(max_rows=15))\n",
    "    \n",
    "\n",
    "# Combine DataFrames along the second axis (columns)\n",
    "result208_df = pd.concat([dfs208_list[0], dfs208_list[-1]], axis=1)\n",
    "result208all_df = pd.concat(dfs208_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b0a03",
   "metadata": {},
   "source": [
    "<a id='208Threshold'></a>\n",
    "### 2.2.2 Iterative 208Pb correction - number of iterations set by threshold\n",
    "\n",
    "Loops iterations until either the threshold or num_iterations is reached. The threshold is defined as the percent difference in the corrected date between the current and previous iteration (i.e., 1%). If the date difference is above the threshold for any grains, another iteration will run for all grains.\n",
    "\n",
    "Note: All iteration results are displayed but only the first and last are included in the export table (Sections 2.3 and 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = 200  # Set a large number to ensure it runs until the threshold is met, may need to increase\n",
    "\n",
    "# Specify the threshold\n",
    "threshold = 1 / 100  # ex: 1% expressed as a decimal\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dfs208_list = []\n",
    "\n",
    "# Initial date estimate\n",
    "date_estimate = t638  # iteration 1 uses uncorrected date, subsequent iterations use date calculated in the previous iteration\n",
    "date_estimate = np.where(date_estimate > 4570, 4570, date_estimate)\n",
    "\n",
    "# Initialize iteration counter\n",
    "iteration = 1\n",
    "\n",
    "# Perform iterations\n",
    "while iteration <= num_iterations:\n",
    "    # Perform 208Pb correction for the current iteration\n",
    "    current_iteration_results = iterative_208Pb(date_estimate, i638, i638err)\n",
    "    \n",
    "    # Create a DataFrame for the current iteration results\n",
    "    df_iteration = pd.DataFrame(\n",
    "        current_iteration_results,\n",
    "        columns=[f\"208It{iteration}_208/206c\", f\"208It{iteration}_208/206*\",\n",
    "                 f\"208It{iteration}_f206\", f\"208It{iteration}_206*/238\",\n",
    "                 f\"208It{iteration}_DateTot206\", f\"208It{iteration}_Date208c\",\n",
    "                 f\"208It{iteration}_Date208cErr\", f\"208It{iteration}_AgeDiffCorr\"]\n",
    "    )\n",
    "    \n",
    "    # Print information about the current iteration\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {iteration} Complete\\033[0m')\n",
    "    print('Date of grain in last row (Ma):', current_iteration_results[-1, 5])\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs208_list.append(df_iteration)\n",
    "    \n",
    "    # Check if the condition is met for all rows\n",
    "    if iteration > 1:\n",
    "        date_difference = abs(current_iteration_results[:, 5] - dfs208_list[-2].iloc[:, 5])\n",
    "        if all(date_diff < threshold for date_diff in date_difference):\n",
    "            break  # Exit the loop if the condition is met for all rows\n",
    "\n",
    "    # Update the date_estimate for the next iteration\n",
    "    date_estimate = current_iteration_results[:, 5]\n",
    "\n",
    "    # Increment the iteration counter\n",
    "    iteration += 1\n",
    "    \n",
    "    \n",
    "# Display the DataFrames\n",
    "print('\\n\\n *Preview of results from every iteration:* \\n')\n",
    "for i, result208_df in enumerate(dfs208_list, start=1):\n",
    "    print(f'\\n\\n\\033[1m207Pb Correction - Iteration {i} Results DataFrame:\\033[0m')\n",
    "    print('\\ncolumns: 1- 208/206 common, 2- 208/206* radiogenic, 3- Fraction common Pb (f206), 4- 206*/238 ratio, 5- Total 206 Date (Ma), 6- 208Pb-corrected date (Ma), 7- 208Pb-corrected date uncertainty (2s abs), 8- Difference in 208Pb corr from total206 dates (Ma) \\n\\n')\n",
    "    print(result208_df.to_string(max_rows=15))\n",
    "\n",
    "# Concatenate the first and last iterations into a new DataFrame\n",
    "result208_df = pd.concat([dfs208_list[0], dfs208_list[-1]], axis=1)\n",
    "result208all_df = pd.concat(dfs208_list, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4907be",
   "metadata": {},
   "source": [
    "## 2.3 Save 208Pb Correction Results\n",
    "Run the cell below to concatenate the input table and 208Pb correction tables, then save to Excel file\n",
    "\n",
    "*Note: Saves most recently run 208Pb correction results from either the manual iteration ([Section 2.2.1](#208Manual)) or threshold iteration ([Section 2.2.2](#208Threshold)). Does not save both. The exported table includes all iteration results from manual iteration OR only the first and last iterations from the threshold iteration (save all iterations in [Section 4](#Section4)).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine 208Pb Correction iteration outputs into final table, concatenate with input table\n",
    "### Will be prompted whether want to save file yes/no below, then window will open to save\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "user_input = input(\"\\033[1mDo you want to save to Excel? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n Either way, will display DataFrame \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"OutputFile_208Correction_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the DataFrame to Excel\n",
    "    if file_path:\n",
    "        result208_df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved to Excel:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "\n",
    "\n",
    "# Display the concatenated DataFrame \n",
    "print('\\n\\n\\033[1mConcatenated DataFrame with 208Pb Correction Results:')\n",
    "pd.set_option('display.max_columns', None)\n",
    "result208_df.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b87612",
   "metadata": {},
   "source": [
    "<a id='Section3'></a>\n",
    "# 3. 207 Pb Correction\n",
    "Iteratively calculate 207Pb-corrected age\n",
    "\n",
    "The 207Pb correction method is based on a linear regression of 207Pb/206Pb and 238U/206Pb in Tera-Wasserburg space (Tera and Wasserburg, 1972) along a two-component mixing line between non-radiogenic and radiogenic Pb (Faure, 1986). The 207Pb correction method assumes U-Pb concordance and no Pb loss but, unlike the 208Pb correction, does not assume U/Th remained closed. Because Pb loss is not considered, all corrected dates are (possibly) minimum ages. \n",
    "\n",
    "The 207Pb correction iterates on initial age and Stacey and Kramers (1975) terrestrial Pb evolution model. The measured isotopes are the iolite baseline-corrected CPS values (defined in [Section 1](#DefineVariables)). The initial age is the uncorrected date, which is then replaced by the result of subsequent iterations. For the 2 stage terrestrial Pb evolution model of Stacey and Kramers (1975, EPSL), 3700 Ma is the boundary between the first and second stages. If the initial date is > 4570 Ma, it is set to 4570 Ma.\n",
    "\n",
    "The 207Pb correction is discussed extensively in the literature: Faure (1986), Williams (1997), Ludwig (1998), see also Chew et al. (2011), Thomson et al. (2012), Smye and Stockli (2014), and Vermeesch (2020). The equations below are modified from the Excel routine of Stuart Thomson and benefitted from discussions with Drew Levy, Lisa Stockli, and Zach Foster-Beril.\n",
    "\n",
    "## 3.1 Define 207Pb Correction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3519e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for 207 Pb correction\n",
    "# Only need to run this once per session\n",
    "\n",
    "# 207 Pb Correction\n",
    "def iterative_207Pb(initial_age, i638_values, i638err_values):\n",
    "    result_array = np.zeros((len(initial_age), 6))\n",
    "\n",
    "    # Iterative section for 207Pb Correction\n",
    "    for i in range(len(initial_age)):\n",
    "        # Calculate initial common Pb section\n",
    "        # 1st stage Pb evolution from Stacey & Kramers 1975 EPSL (Table 8)\n",
    "        if (initial_age[i] > 0.0) & (~np.isnan(initial_age[i])): # Check for NaN or zero values in initial_age\n",
    "            if initial_age[i] > 3700:\n",
    "                a64 = 7.19 * (np.exp(lambda238 * 4.570E9) - np.exp(lambda238 * initial_age[i] * 1000000)) + 9.307\n",
    "                a74 = (7.19 / rat85) * (np.exp(lambda235 * 4.570E9) - np.exp(lambda235 * initial_age[i] * 1000000)) + 10.294\n",
    "                a76 = a74 / a64 # 207/206 common\n",
    "            else:\n",
    "                # 2nd stage Pb evolution from Stacey & Kramers 1975 EPSL (Eqns 5-6; Table 8); see also McLean et al 2011 G3 (Eqns A28-A30); and Vermeesch 2020 Geochron (Eqns 25-26)\n",
    "                a64 = 9.74 * (np.exp((lambda238 * 3.7E9)) - np.exp((lambda238 * initial_age[i] * 1000000))) + 11.152 # 206/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "                a74 = (9.74 / rat85) * (np.exp((lambda235 * 3.7E9)) - np.exp((lambda235 * initial_age[i] * 1000000))) + 12.998 # 207/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "                a76 = a74 / a64 # 207/206 common\n",
    "        else:\n",
    "            result_array[i, :] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            pass\n",
    "\n",
    "        # 207 Pb correction\n",
    "        if (initial_age[i] > 0.0) & (~np.isnan(initial_age[i])):\n",
    "            # calculate expected radiogenic Pb ratios: 207Pb* / 206Pb* = (235/238 U ratio) [(eλ235 t* -1) / (eλ238 t* -1)] \n",
    "            cc = (np.exp(lambda235 * (initial_age[i] * 1000000))) - 1 # 207Pb produced from initial age estimate\n",
    "            dd = (np.exp(lambda238 * (initial_age[i] * 1000000))) - 1 # 206Pb produced from initial age estimate\n",
    "            c76Pb = rat58 * (cc / dd) # expected radiogenic Pb 207Pb* / 206Pb*\n",
    "\n",
    "            # calculate f206, fraction of common Pb\n",
    "            #gg = R[i, 4] # recall 207/206 Pb ratio calculated from CPS\n",
    "            gg = i76[i] # use inital 207/206 ratio from data reduction (rather than re-calculated from CPS)\n",
    "            f206_207 = (gg - c76Pb) / (a76 - c76Pb) # f206 = (meas. - expected)/(common - expected)\n",
    "            Rad638_207 = (1 - f206_207) * i638[i] # Radiogenic component, 206*/238 ratio\n",
    "\n",
    "            if (Rad638_207 + 1) > 0:\n",
    "                # solve age equation with corrected radiogenic 206*/238 ratio to get the corrected age: t = ln ( 206/238 + 1 ) / λ238\n",
    "                CorrDate_207 = ((np.log(Rad638_207 + 1)) / lambda238) / 1000000 # Corrected date\n",
    "\n",
    "                # calculate 2SE abs error of 208corrected age using initial % error\n",
    "                pp = i638[i] # recall initial Final 206/238 ratio\n",
    "                qq = i638err[i] #recall initial Final 206/238 error 2SE abs\n",
    "                CorrDateErr_207 = CorrDate_207 / 100 * (qq / pp * 100) # calculate 2SE abs error of corrected age using initial % error\n",
    "\n",
    "                # Store results in the array\n",
    "                result_array[i, :] = [a76, c76Pb, f206_207, Rad638_207, CorrDate_207, CorrDateErr_207]\n",
    "            else:\n",
    "                result_array[i, :] = [a76, c76Pb, f206_207, Rad638_207, np.nan, np.nan]\n",
    "\n",
    "        else:\n",
    "            result_array[i, :] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            pass # Handle the case where i638[i] is zero\n",
    "\n",
    "    return result_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff6a38",
   "metadata": {},
   "source": [
    "## 3.2 Perform Iterative 207Pb Correction\n",
    "<a id='207Manual'></a>\n",
    "### 3.2.1 Iterative 207Pb correction - the number of iterations are defined manually\n",
    "\n",
    "At least 5 iterations is recommended. Chew et al. (2011) demonstrate that the choice of initial age results in a < 0.05% difference in the final 207Pb-corrected age after 5 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative 207Pb correction \n",
    "\n",
    "# Define number of iterations\n",
    "num_iterations = 5\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dfs207_list = []\n",
    "\n",
    "# Initial date estimate\n",
    "date_estimate = t638 # iteration 1 uses uncorrected date, subsequent iterations use date calculated in previous iteration\n",
    "date_estimate = np.where(date_estimate > 4570, 4570, date_estimate)\n",
    "\n",
    "# Perform iterations\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    # Perform 207Pb correction for the current iteration\n",
    "    current_iteration_results = iterative_207Pb(date_estimate, i638, i638err)\n",
    "    \n",
    "    # Create a DataFrame for the current iteration results\n",
    "    df_iteration = pd.DataFrame(\n",
    "        current_iteration_results,\n",
    "        columns=[f\"207It{iteration}_207/206c\", f\"207It{iteration}_207/206*\",\n",
    "                 f\"207It{iteration}_f206\", f\"207It{iteration}_206*/238\",\n",
    "                 f\"207It{iteration}_Date207c\", f\"207It{iteration}_Date207cErr\"]\n",
    "    )\n",
    "    \n",
    "    # Print information about the current iteration\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {iteration} Complete\\033[0m')\n",
    "    print('Date of grain in last row (Ma):', current_iteration_results[-1, 4])\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs207_list.append(df_iteration)\n",
    "    \n",
    "    # Update the date_estimate for the next iteration\n",
    "    date_estimate = current_iteration_results[:, 4]\n",
    "\n",
    "# Display the DataFrames\n",
    "print('\\n\\n *Preview of results from every iteration:* \\n')\n",
    "for i, result207_df in enumerate(dfs207_list, start=1):\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {i} Results DataFrame:\\033[0m')\n",
    "    print('columns: 1- 207/206 common, 2- 207/206* radiogenic, 3- Fraction common Pb (f206), 4- Radiogenic component, 206*/238 ratio, 5- 207Pb-corrected date (Ma), 6- 207Pb-corrected date uncertainty (2s abs)\\n\\n')\n",
    "    print(result207_df.to_string(max_rows=15))\n",
    "    \n",
    "# Combine DataFrames along the second axis (columns)\n",
    "result207_df = pd.concat([dfs207_list[0], dfs207_list[-1]], axis=1)\n",
    "result207all_df = pd.concat(dfs207_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bebde7",
   "metadata": {},
   "source": [
    "<a id='207Threshold'></a>\n",
    "### 3.2.2 Iterative 207Pb correction - the number of iterations set by threshold\n",
    "\n",
    "Loops iterations until either the threshold or num_iterations is reached. The threshold is defined as the percent difference in the corrected date between the current and previous iteration (i.e., 1%). If the date difference is above the threshold for any grain, another iteration will run for all grains.\n",
    "\n",
    "*Note: All iteration results are displayed but only the first and last are included in the export table (Sections 3.3 and 3.4). Save all iterations in [Section 4](#Section4).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b193ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try iteration with threshold\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 200  # Set a large number to ensure it runs until the threshold is met, may need to increase\n",
    "\n",
    "# Specify the threshold\n",
    "threshold = 1 / 100  # 1% expressed as a decimal\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dfs207_list = []\n",
    "\n",
    "# Initial date estimate\n",
    "date_estimate = t638  # iteration 1 uses uncorrected date, subsequent iterations use date calculated in the previous iteration\n",
    "date_estimate = np.where(date_estimate > 4570, 4570, date_estimate)\n",
    "\n",
    "# Initialize iteration counter\n",
    "iteration = 1\n",
    "\n",
    "# Perform iterations\n",
    "while iteration <= num_iterations:\n",
    "    # Perform 207Pb correction for the current iteration\n",
    "    current_iteration_results = iterative_207Pb(date_estimate, i638, i638err)\n",
    "\n",
    "    # Create a DataFrame for the current iteration results\n",
    "    df_iteration = pd.DataFrame(\n",
    "        current_iteration_results,\n",
    "        columns=[f\"207It{iteration}_207/206c\", f\"207It{iteration}_207/206*\",\n",
    "                 f\"207It{iteration}_f206\", f\"207It{iteration}_206*/238\",\n",
    "                 f\"207It{iteration}_Date207c\", f\"207It{iteration}_Date207cErr\"]\n",
    "    )\n",
    "\n",
    "    # Print information about the current iteration\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {iteration} Complete\\033[0m')\n",
    "    print('Date of grain in the last row (Ma):', current_iteration_results[-1, 4])\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dfs207_list.append(df_iteration)\n",
    "\n",
    "    # Check if the condition is met for all rows\n",
    "    if iteration > 1:\n",
    "        date_difference = abs(current_iteration_results[:, 4] - dfs207_list[-2].iloc[:, 4])\n",
    "        if all(date_diff < threshold for date_diff in date_difference):\n",
    "            break  # Exit the loop if the condition is met for all rows\n",
    "\n",
    "    # Update the date_estimate for the next iteration\n",
    "    date_estimate = current_iteration_results[:, 4]\n",
    "\n",
    "    # Increment the iteration counter\n",
    "    iteration += 1\n",
    "\n",
    "# Display the DataFrames\n",
    "print('\\n\\n *Preview of results from every iteration:* \\n')\n",
    "for i, result207_df in enumerate(dfs207_list, start=1):\n",
    "    print(f'\\n\\033[1m207Pb Correction - Iteration {i} Results DataFrame:\\033[0m')\n",
    "    print('columns: 1- 207/206 common, 2- 207/206* radiogenic, 3- Fraction common Pb (f206), 4- 207Pb-corrected date (Ma), 5- 207Pb-corrected date uncertainty (2s abs)\\n\\n')\n",
    "    print(result207_df.to_string(max_rows=15))\n",
    "\n",
    "# Concatenate the first and last iterations into a new DataFrame\n",
    "result207_df = pd.concat([dfs207_list[0], dfs207_list[-1]], axis=1)\n",
    "result207all_df = pd.concat(dfs207_list, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c813269",
   "metadata": {},
   "source": [
    "## 3.3 Save 207Pb Correction Results\n",
    "Run the cell below to concatenate the input table and 207Pb-correction tables, then save to Excel file.\n",
    "\n",
    "*Note: Saves most recently run 207Pb correction results from either the manual iteration ([Section 3.2.1](#207Manual)) or threshold iteration ([Section 3.2.2](#207Threshold)). Does not save both. The exported table includes all iteration results from manual iteration OR only the first and last iterations from the threshold iteration (save all iterations in [Section 4](#Section4)).*\n",
    "\n",
    "The 207Pb correction results can be used to calculate discordance in the notebook UPb-Plotter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine 207Pb Correction iteration outputs into final table, concatenate with input table\n",
    "### Will be prompted whether want to save file yes/no below, then window will open to save\n",
    "\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "user_input = input(\"\\033[1mDo you want to save to Excel? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n Either way, will display DataFrame \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"OutputFile_207Correction_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the DataFrame to Excel\n",
    "    if file_path:\n",
    "        result207_df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved to Excel:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "\n",
    "\n",
    "# Display the concatenated DataFrame \n",
    "pd.set_option('display.max_columns', None)\n",
    "print('\\n\\n\\033[1mConcatenated DataFrame with 207Pb Correction Results:')\n",
    "result207_df.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655a9d7",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "# 4. Export Combined 208Pb and 207Pb Correction Results\n",
    "Run the cell below to concatenate the input table, 208Pb-correction tables and 207Pb-correction tables, then save to Excel file\n",
    "\n",
    "Note: Saves the 208Pb and 207Pb correction tables most recently run, *not both* the manual and threshold iteration tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98a94f",
   "metadata": {},
   "source": [
    "## 4.1 View and save results - first and last iteration\n",
    "\n",
    "View results of first and last iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View 208Pb correction results\n",
    "\n",
    "result208_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View 207Pb correction results\n",
    "\n",
    "result207_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819b64b",
   "metadata": {},
   "source": [
    "Save results of first and last iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine 208Pb and 207Pb Correction iteration outputs into final table, concatenate with input table\n",
    "### Will be prompted whether want to save file yes/no below, then window will open to save\n",
    "\n",
    "# Combine DataFrames along the second axis (columns)\n",
    "result208207_df = pd.concat([df, result208_df, result207_df], axis=1)\n",
    "\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "user_input = input(\"\\033[1mDo you want to save to Excel? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n Either way, will display DataFrame \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"OutputFile_CombinedPbCorrection_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the DataFrame to Excel\n",
    "    if file_path:\n",
    "        result208207_df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved to Excel:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "\n",
    "\n",
    "# Display the concatenated DataFrame \n",
    "pd.set_option('display.max_columns', None)\n",
    "print('\\n\\n\\033[1mConcatenated DataFrame with 208Pb and 207Pb Correction Results:')\n",
    "result208207_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e728c97",
   "metadata": {},
   "source": [
    "## 4.2 View and save results - all iterations\n",
    "\n",
    "View results of all iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View 208Pb correction results, all iterations\n",
    "\n",
    "result208all_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View 207Pb correction results, all iterations\n",
    "\n",
    "result207all_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7ba8b",
   "metadata": {},
   "source": [
    "Save results of all iterations\n",
    "<br> *Note: will create a large file if number of iterations is tens to hundreds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9979f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine 208Pb and 207Pb Correction iteration outputs into final table, concatenate with input table\n",
    "### Will be prompted whether want to save file yes/no below, then window will open to save\n",
    "\n",
    "# Combine DataFrames along the second axis (columns)\n",
    "result208207all_df = pd.concat([df, result208all_df, result207all_df], axis=1)\n",
    "\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "user_input = input(\"\\033[1mDo you want to save to Excel? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save (be patient, large file to save)\\n Either way, will display DataFrame \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"OutputFile_CombinedPbCorrection_AllIterations_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the DataFrame to Excel\n",
    "    if file_path:\n",
    "        result208207all_df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved to Excel:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "\n",
    "\n",
    "# Display the concatenated DataFrame \n",
    "pd.set_option('display.max_columns', None)\n",
    "print('\\n\\n\\033[1mConcatenated DataFrame with 207Pb Correction Results:')\n",
    "result208207all_df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
