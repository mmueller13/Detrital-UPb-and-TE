{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6666d4c0",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Rutile-Trace-Elements</div>\n",
    "## <div align=\"center\">Python code for visualizing detrital rutile trace element geochemistry data</div>\n",
    "#### <div align=\"center\">Megan Mueller</div>\n",
    "##### <div align=\"center\">Please cite the accompanying article published in Geochronology:</div>\n",
    "<div align=\"center\">Mueller et al., 2024, https://doi.org/10.5194/gchron-6-265-2024 </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b8d1e",
   "metadata": {},
   "source": [
    "# Overview \n",
    "This notebook produces various plots for visualizing trace element data from detrital rutile. \n",
    "\n",
    "### Initial Conditions\n",
    "The notebook uses the Excel file with results from several other notebooks: corrected U-Pb date and uncertainty from the Detrital-Common-Pb-Corrections notebook and percent concordant from the UPb-Plotter notebook.\n",
    "\n",
    "The code uses colorblind-friendly color maps from Fabio Crameri (https://www.fabiocrameri.ch/colourmaps/)\n",
    "\n",
    "### Organization\n",
    "This notebook is divided into the following sections: \n",
    "1. [Data import and initial code](#Section1) (must run first) \n",
    "2. [TiO2 polymorphs](#Section2)\n",
    "3. [Mafic vs pelitic protoliths](#Section3)\n",
    "4. [Zr-in-rutile thermometry](#Section4)\n",
    "5. [Low U rutile](#Section5)\n",
    "6. [Evaluating potential bias](#Section6) \n",
    "7. [Export data](#Section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311d94a",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "# 1. Import Data and Set-Up\n",
    "\n",
    "\n",
    "### 1.1 Install Python Packages and Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e942bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Python packages\n",
    "# Run to see if installed, if not, will install\n",
    "# Only need to install once\n",
    "\n",
    "import importlib\n",
    "from subprocess import run\n",
    "\n",
    "def install_if_not_installed(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"Package {package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing package: {package_name}\")\n",
    "        run(['pip', 'install', package_name], check=True)\n",
    "        print(f\"Installed package: {package_name}\")\n",
    "\n",
    "install_if_not_installed(\"pandas\") # Install pandas\n",
    "install_if_not_installed(\"numpy\") # Install numpy\n",
    "install_if_not_installed(\"matplotlib\") # Install matplotlib\n",
    "install_if_not_installed(\"tabulate\") # Install tabulate\n",
    "install_if_not_installed(\"sympy\") # Install sympy\n",
    "install_if_not_installed(\"easygui\") # Install easygui\n",
    "install_if_not_installed(\"cmcrameri\") # Install cmcrameri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from sympy import symbols, Eq, solve, exp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import easygui\n",
    "from cmcrameri import cm\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef1194",
   "metadata": {},
   "source": [
    "### 1.2 Input File Organization (Data Needed to Run)\n",
    "In addition to trace element concentations, the following sections of code use the following data: 238/206 and 207/206 ratios, U (ppm), 207Pb-corrected age and uncertainty, and percent discordant and concordant. The UPbPlotter outut table should be used as the input file which has all of the relecant columns, or can load multiple Excel spreadsheets.\n",
    "\n",
    "The cell below can be modified to run in one of two ways: (1) import one Excel file with trace element data and U-Pb data, or (2) import two Excel files with trace element and U-Pb data separately. If importing 2 Excel files, the code will combine into one file, so must have same number of rows and same grain in each row. The code will prompt the user to answer whether there are one or two files to import. Code will not continue without completing prompt.\n",
    "\n",
    "Data needed to run:\n",
    "- Grain information (i.e., grain name, sample name, stratigraphic position)\n",
    "- Trace element concentrations as ppm\n",
    "- U concentration as ppm\n",
    "- 238/206 and 207/206 ratios and uncertainties\n",
    "- 207Pb corrected date and uncertainty (from Detrital-Common-Pb-Corrections)\n",
    "- Percent concordance and discordance (Stacey-Kramers metric, from UPb-Plotter)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd89362",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Load Excel file with data into DataFrame\n",
    "\n",
    "# Edit the following lines to direct to the Excel file with trace element data\n",
    "folder_path1 = r'C:\\Users\\megan\\Dropbox\\CommonPbPython\\Example-data'   # Update this with the actual path\n",
    "file_name1 = 'ExampleData-RutileTraceElements-Muelleretal.xlsx'  # Update this with the actual first file name\n",
    "sheet_name1 = 'Sheet1' # Sheet name in Excel file\n",
    "\n",
    "excel_file_path1 = os.path.join(folder_path1, file_name1) # Combine folder path and file name using os.path.join\n",
    "df1 = pd.read_excel(excel_file_path1, sheet_name=sheet_name1) # Load the first file into a DataFrame\n",
    "\n",
    "user_input = input(\"\\033[1mWould you like to import one or two Excel files (1/2): \\033[0m\\n type '1' or '2' not 'one' or 'two' \\n If 1, that means that all TE and U-Pb data are together in one Excel file. \\n If 2, can import two Excel files: one with TE and another with U-Pb.\\n *Note: if loading 2 files, the same grain must be in each row \\n\")\n",
    "if user_input.lower() == '1':\n",
    "    df = df1\n",
    "    print(\"\\033[1m1 Excel file loaded\\033[0m\")\n",
    "elif user_input == '2':\n",
    "    # Specify the folder and file names for the second file that contains U-Pb data if not in first file\n",
    "    folder_path2 = r'path\\to\\second\\folder'  # Update this with the actual path\n",
    "    file_name2 = 'file_name.xlsx'  # Update this with the actual second file name\n",
    "    sheet_name2 = 'Sheet1' # Update this with the actual sheet name of the second file\n",
    "\n",
    "    excel_file_path2 = os.path.join(folder_path2, file_name2) # Combine folder path and file name using os.path.join\n",
    "    df2 = pd.read_excel(excel_file_path2, sheet_name=sheet_name2) # Load the second file into a DataFrame\n",
    "\n",
    "    df = pd.concat([df1, df2], ignore_index=True)     # Combine DataFrames\n",
    "    print(\"\\033[1m2 Excel files loaded.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mOops. Invalid input. Please enter '1' or '2'.\\033[0m\")\n",
    "    \n",
    "\n",
    "# Display the combined DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(15)  # display first 10 rows of the combined DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e47d7b",
   "metadata": {},
   "source": [
    "<a id='DefineVariables'></a>\n",
    "### 1.3 Define Variables\n",
    "Edit DataFrame column header names as needed. Prompts user to answer whether input uncertainties are 1s absolute or 2s absolute. If 1s, will convert to 2s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this section to add/remove columns to include as variables\n",
    "# Everything here will be used in subsequent code\n",
    "# Edit if column names are different than below. See column names in above cell output (or, run df.head(15) )\n",
    "\n",
    "# Define variables by column headers\n",
    "data_dict = df.to_dict(orient='series')\n",
    "\n",
    "# Grain Information\n",
    "# Load these if want to explore them in plots (i.e., color grains by Stratigraphic Position)\n",
    "StratOrder = df['Stratigraphic Position']\n",
    "GrainID = df['Grain_ID']\n",
    "RunID = df['Analytical Run'] # not used, but provided as example\n",
    "SampleID = df['Sample_ID'] # not used, but provided as example\n",
    "\n",
    "# Trace elements\n",
    "# Edit to include at least the following elements\n",
    "V = df['V'].copy()\n",
    "Cr = df['Cr'].copy()\n",
    "Zr = df['Zr'].copy()\n",
    "Nb = df['Nb'].copy()\n",
    "Ta = df['Ta'].copy()\n",
    "U = df['Approx_U_PPM_mean'].copy()\n",
    "\n",
    "# U-Pb data: Initial measured and calculated values\n",
    "# Can use 207Pb-corrected output table as input file\n",
    "i386 = df['Final U238/Pb206_mean'].copy()\n",
    "i386err = df['Final U238/Pb206_2SE(prop)'].copy() # absolute\n",
    "i76 = df['Final Pb207/Pb206_mean'].copy()\n",
    "i76err = df['Final Pb207/Pb206_2SE(prop)'].copy() # absolute\n",
    "XsErrPerc = i386err / i386 * 100 # define percent uncertainty\n",
    "YsErrPerc = i76err / i76 * 100 # define percent uncertainty\n",
    "\n",
    "# Pb Corrected Date\n",
    "Date207c = df['207It200_Date207c'].copy() # Load column with final iteration 207Pb-corrected date\n",
    "Date207c_err = df['207It200_Date207cErr'].copy() # Load column with final iteration 207Pb-corrected date uncertainty\n",
    "Date207c_err_perc = Date207c_err / Date207c * 100\n",
    "\n",
    "# Concordance and Discordance\n",
    "PercDisc = df['SK_percent_discordant'].copy() # Percent discordant\n",
    "PercConc = df['SK_percent_concordant'].copy()\n",
    "\n",
    "\n",
    "# Check if uncertainties are 2s abs or 1s abs\n",
    "user_input = input(\"\\033[1mAre input file U-Pb ratio uncertainties 1-sigma absolute or 2-sigma absolute? \\033[0m\\n Type '1' or '2' (not 'one' or 'two') \\n If 2, no calculations will be performed \\n If 1, input uncertainties will be multiplied by 2 \\n\")\n",
    "if user_input.lower() == '2':\n",
    "    print(\"\\033[1mInput uncertainties are 2s\\033[0m\")\n",
    "elif user_input == '1':\n",
    "    # Will run the following code if input uncertainties are 1s (abs) and not 2s (abs)\n",
    "    i386err = i386err * 2 # 2s absolute\n",
    "    i76err = i76err * 2 # 2s absolute\n",
    "    XsErrPerc = XsErrPerc * 2 # 2s percent\n",
    "    YsErrPerc = YsErrPerc * 2 # 2s percent\n",
    "    #Date207c_err = Date207c_err * 2 # Pb correction notebook is already at 2s, so only run this if load other date uncertainty\n",
    "    print('\\033[1mReminder:\\033[0m Input uncertainties are 1s and were multiplied by 2. Subsequent calculations and outputs will be at 2s level')\n",
    "else:\n",
    "    print(\"\\033[1mOops. Invalid input. Please enter '1' or '2'.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60471fca",
   "metadata": {},
   "source": [
    "<a id='ConcordiaPoints'></a>Define constants and initial calculations. Define age points along concordia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and initial calculations\n",
    "\n",
    "# Define constants\n",
    "instUTh = 1; # instrument-specific U/Th, should be =1 and already corrected during data reduction\n",
    "rat85 = 137.88; # 238U/235U ratio. 137.88 from Steiger and Jäger (1977). 137.818 from Hiess et al. (2012). \n",
    "rat58 = 0.007252683; # 1/137.88 constant 235/238 U ratio\n",
    "lambda238 = 1.55125E-10; # U238 decay constant from Faure (1986)\n",
    "lambda235 = 9.8485E-10; # U235 decay constant from Faure (1986)\n",
    "lambda232 = 4.9475E-11; # 232Th decay constant\n",
    "\n",
    "# Set up concordia curve for subsequent plots\n",
    "t = np.linspace(1, 6000000000, 1000)  # 1000 points between 1 and 6000000000, time in yrs\n",
    "X86 = 1 / (np.exp(lambda238 * t) - 1)  # 238/206 ratio over time\n",
    "Y76 = (1 / rat85) * (np.exp(lambda235 * t) - 1) / (np.exp(lambda238 * t) - 1)  # 207/206 ratio over time\n",
    "\n",
    "# Mark some points along the line at specified times\n",
    "# Can edit to change which Date markers are displayed on concordia curve\n",
    "tMyr = np.array([50e6, 75e6, 100e6, 200e6, 350e6, 500e6, 750e6, 1000e6, 2000e6, 3000e6, 4000e6])\n",
    "X86tMyr = 1 / (np.exp(lambda238 * tMyr) - 1)  # 238/206 ratio at specified time\n",
    "Y76tMyr = (1 / rat85) * (np.exp(lambda235 * tMyr) - 1) / (np.exp(lambda238 * tMyr) - 1)  # 207/206 ratio at specified time\n",
    "\n",
    "# Initial calculations\n",
    "logV = np.log10(V)\n",
    "logCr = np.log10(Cr)\n",
    "logZr = np.log10(Zr)\n",
    "CrNb = Cr / Nb\n",
    "logCrNb = np.log10(Cr / Nb)\n",
    "NbTa = Nb / Ta\n",
    "\n",
    "# Uncorrected U-Pb points used in subsequent plots\n",
    "Xs386 = i386 # avoid overwriting\n",
    "Ys76 = i76\n",
    "Xs386[Xs386 == 0] = np.nan # replace 0.0 values with NaN\n",
    "Ys76[Ys76 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b4cff",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "# 2. TiO2 Polymorphs\n",
    "\n",
    "This section uses the trace element data to discriminate TiO2 polymorphs following Triebold et al. (2011). The second section replicates the first's plot with the inclusion of the TiO2 polymorph dataset of Triebold et al. (2011).\n",
    "\n",
    "### 2.1 TiO2 Polymorph Plots using Cr, Zr, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TiO2 Polymorphs\n",
    "# Define the color of points in plot, suggested Stratigraphic Position\n",
    "# Edit as needed\n",
    "color_variable = df['Stratigraphic Position'].copy() # Variable to color points. Change to desired input table heading\n",
    "color_label = 'Stratigraphic Position' # Color bar label\n",
    "color_variable = pd.to_numeric(color_variable, errors='coerce')\n",
    "palette = 'gist_earth' #cm.batlowW, 'cubehelix'\n",
    "\n",
    "# Calculate rounded min and max values\n",
    "min_logV = np.floor(np.min(logV) / 0.5) * 0.5\n",
    "max_logV = np.ceil(np.max(logV) / 0.5) * 0.5\n",
    "min_logCr = np.floor(np.min(logCr) / 0.5) * 0.5\n",
    "max_logCr = np.ceil(np.max(logCr) / 0.5) * 0.5\n",
    "min_logZr = np.floor(np.min(logZr) / 0.5) * 0.5\n",
    "max_logZr = np.ceil(np.max(logZr) / 0.5) * 0.5\n",
    "\n",
    "# log(V-ppm) vs log(Cr-ppm)\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "s1 = sns.scatterplot(x=logV, y=logCr, hue=color_variable, palette=palette, edgecolor='k', s=50, legend=False, ax=axes[0])\n",
    "sm = plt.cm.ScalarMappable(cmap=palette, norm=plt.Normalize(vmin=color_variable.min(), vmax=color_variable.max()))\n",
    "sm.set_array([])  # An empty array is required\n",
    "colorbar = plt.colorbar(mappable=sm, ax=axes[0])\n",
    "colorbar.set_label(color_label, rotation=270, labelpad=15)\n",
    "colorbar.set_ticks(color_variable.unique())  # Set ticks to 'StratPos' values\n",
    "axes[0].set_title('log(V-ppm) vs log(Cr-ppm) after Triebold et al. 2011')\n",
    "axes[0].set_xlabel('log(V [ppm])')\n",
    "axes[0].set_ylabel('log(Cr [ppm])')\n",
    "axes[0].set_xlim(min_logV, max_logV)\n",
    "axes[0].set_ylim(min_logCr, max_logCr)\n",
    "axes[0].grid(False)\n",
    "\n",
    "# log(Zr) vs log(V)\n",
    "s2 = sns.scatterplot(x=logZr, y=logV, hue=color_variable, palette=palette, edgecolor='k', s=50, legend=False, ax=axes[1])\n",
    "sm = plt.cm.ScalarMappable(cmap=palette, norm=plt.Normalize(vmin=color_variable.min(), vmax=color_variable.max()))\n",
    "sm.set_array([])  # An empty array is required\n",
    "colorbar = plt.colorbar(mappable=sm, ax=axes[1])\n",
    "colorbar.set_label(color_label, rotation=270, labelpad=15)\n",
    "colorbar.set_ticks(color_variable.unique())  # Set ticks to 'StratPos' values\n",
    "axes[1].set_title('log(Zr-ppm) vs log(V-ppm) after Triebold et al. 2011')\n",
    "axes[1].set_xlabel('log(Zr [ppm])')\n",
    "axes[1].set_ylabel('log(V [ppm])')\n",
    "axes[1].set_xlim(min_logZr, max_logZr)\n",
    "axes[1].set_ylim(min_logV, max_logV)\n",
    "axes[1].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fe299",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "# Run immediately after generating figure or might save a different figure instead\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"TiO2_polymorphs_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1810f1",
   "metadata": {},
   "source": [
    "### 2.2 Plot with Polymorph Dataset\n",
    "The following cells repeats the above plot with the addition of the Triebold et al. (2011) TiO2 polymorphs dataset. Grains in this dataset were classified using Raman spectroscopy and give a general sense for where rutile should plot. 1. Load Triebold et al. 2011 dataset; 2. plot; 3. save figure.\n",
    "\n",
    "*Triebold, S., Luvizotto, G. L., Tolosana-Delgado, R., Zack, T., & von Eynatten, H. (2011). Discrimination of TiO2 polymorphs in sedimentary and metamorphic rocks. Contributions to Mineralogy and Petrology, 161(4), 581–596. https://doi.org/10.1007/s00410-010-0551-x*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot TiO2 polymorphs with Triebold et al. 2011 dataset\n",
    "\n",
    "# Import Triebold et al. 2011 anatase, brookite, rutile dataset\n",
    "# Edit the following lines to direct to the Excel file with trace element data\n",
    "folder_path_Triebold = r'C:\\Users\\megan\\Dropbox\\CommonPbPython\\Example-data'  # Update this with the actual path\n",
    "file_name_Triebold = 'Triebold_etal_2011_Data.xlsx'  # Update this with the actual file name\n",
    "sheet_name_Triebold = 'Combined' # Sheet name in Excel file, 'Combined' is the combined supplementary data tables OM1 & OM2\n",
    "\n",
    "excel_file_path_Triebold = os.path.join(folder_path_Triebold, file_name_Triebold) # Combine folder path and file name using os.path.join\n",
    "df_Triebold = pd.read_excel(excel_file_path_Triebold, sheet_name=sheet_name_Triebold) # Load the first file into a DataFrame\n",
    "\n",
    "logV_Triebold = df_Triebold['log(V)']\n",
    "logCr_Triebold = df_Triebold['log(Cr)']\n",
    "logZr_Triebold = df_Triebold['log(Zr)']\n",
    "\n",
    "# Display the combined DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_Triebold.head(10)  # display first 10 rows of the combined DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de38277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the color of points in plot, suggested Stratigraphic Position\n",
    "# Edit as needed\n",
    "color_variable = df['Stratigraphic Position'].copy() # Variable to color points by. Change as needed\n",
    "color_label = 'Stratigraphic Position' # Color bar label\n",
    "color_variable = pd.to_numeric(color_variable, errors='coerce')\n",
    "palette = 'gist_earth' #cm.batlowW, 'cubehelix'\n",
    "\n",
    "# Set markers for Triebold et al 2011 data set\n",
    "df_Triebold['Marker'] = np.select(\n",
    "    [df_Triebold['Raman Mineral ID'] == 'Anatase',\n",
    "     df_Triebold['Raman Mineral ID'] == 'Brookite',\n",
    "     df_Triebold['Raman Mineral ID'] == 'Rutile'],\n",
    "    ['*', 'o', 'x'],\n",
    "    default='.'\n",
    ")\n",
    "\n",
    "# Calculate rounded min and max values\n",
    "min_logV = np.floor(min(logV.min(), logV_Triebold.min()) / 0.5) * 0.5\n",
    "max_logV = np.ceil(max(logV.max(), logV_Triebold.max()) / 0.5) * 0.5\n",
    "min_logCr = np.floor(min(logCr.min(), logCr_Triebold.min()) / 0.5) * 0.5\n",
    "max_logCr = np.ceil(max(logCr.max(), logCr_Triebold.max()) / 0.5) * 0.5\n",
    "min_logZr = np.floor(min(logZr.min(), logZr_Triebold.min()) / 0.5) * 0.5\n",
    "max_logZr = np.ceil(max(logZr.max(), logZr_Triebold.max()) / 0.5) * 0.5\n",
    "\n",
    "# log(V-ppm) vs log(Cr-ppm)\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "s1 = sns.scatterplot(x=logV, y=logCr, hue=color_variable, palette=palette, edgecolor='k', s=50, legend=False, ax=axes[0], label='This study', zorder=2)\n",
    "sm = plt.cm.ScalarMappable(cmap=palette, norm=plt.Normalize(vmin=color_variable.min(), vmax=color_variable.max()))\n",
    "sm.set_array([])  # An empty array is required\n",
    "colorbar = plt.colorbar(mappable=sm, ax=axes[0])\n",
    "colorbar.set_label(color_label, rotation=270, labelpad=15)\n",
    "colorbar.set_ticks(color_variable.unique())  # Set ticks to 'StratPos' values\n",
    "#axes[0].set_title('log(V-ppm) vs log(Cr-ppm) after Triebold et al. 2011')\n",
    "axes[0].set_xlabel('log(V [ppm])')\n",
    "axes[0].set_ylabel('log(Cr [ppm])')\n",
    "axes[0].set_xlim(min_logV, max_logV)\n",
    "axes[0].set_ylim(min_logCr, max_logCr)\n",
    "axes[0].grid(False)\n",
    "\n",
    "markers = {'Anatase': '+', 'Brookite': 'x', 'Rutile': '1'}\n",
    "alpha_values = {'Anatase': 0.3, 'Brookite': 0.6, 'Rutile': 0.9}  # Adjust alpha values for each category\n",
    "for category, marker in markers.items():\n",
    "    subset = df_Triebold[df_Triebold['Raman Mineral ID'] == category]\n",
    "    axes[0].scatter(subset['log(V)'], subset['log(Cr)'],\n",
    "                    marker=marker, color='gray', s=50, alpha=alpha_values[category], label=f'{category} (Triebold et al., 2011)', zorder=1)\n",
    "\n",
    "# Legend    \n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "legend = axes[0].legend(handles, labels, loc='best', fancybox=True, shadow=False, ncol=1)   \n",
    "\n",
    "\n",
    "# log(Zr) vs log(V)\n",
    "s2 = sns.scatterplot(x=logZr, y=logV, hue=color_variable, palette=palette, edgecolor='k', s=50, legend=False, ax=axes[1], label='This study', zorder=2)\n",
    "sm = plt.cm.ScalarMappable(cmap=palette, norm=plt.Normalize(vmin=color_variable.min(), vmax=color_variable.max()))\n",
    "sm.set_array([])  # An empty array is required\n",
    "colorbar = plt.colorbar(mappable=sm, ax=axes[1])\n",
    "colorbar.set_label(color_label, rotation=270, labelpad=15)\n",
    "colorbar.set_ticks(color_variable.unique())  # Set ticks to 'StratPos' values\n",
    "#axes[1].set_title('log(Zr-ppm) vs log(V-ppm) after Triebold et al. 2011')\n",
    "axes[1].set_xlabel('log(Zr [ppm])')\n",
    "axes[1].set_ylabel('log(V [ppm])')\n",
    "axes[1].set_xlim(min_logZr, max_logZr)\n",
    "axes[1].set_ylim(min_logV, max_logV)\n",
    "axes[1].grid(False)\n",
    "\n",
    "for category, marker in markers.items():\n",
    "    subset = df_Triebold[df_Triebold['Raman Mineral ID'] == category]\n",
    "    axes[1].scatter(subset['log(Zr)'], subset['log(V)'],\n",
    "                    marker=marker, color='gray', s=50, alpha=alpha_values[category], label=f'{category} (Triebold et al., 2011)', zorder=1)\n",
    "\n",
    "# Legend       \n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "#legend = axes[1].legend(handles, labels, loc='best', fancybox=True, shadow=False, ncol=1)   \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"TiO2_polymorphs_Triebold2011Data_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c2c0d",
   "metadata": {},
   "source": [
    "<a id='Section3'></a>\n",
    "\n",
    "# 3. Mafic vs Pelitic Protoliths\n",
    "\n",
    "The following section uses the trace element data to explore whether detrital rutile were derived from metamafic or metapelitic sources.\n",
    "\n",
    "<a id='UPbUncertainty'></a>\n",
    "## 3.1 Protolith Classification\n",
    "This section defines whether grains plot in the mafic or pelitic discrimination field relative to the field boundary from Triebold et al. (2012). Then, the number of mafic, pelitic or No TE points are calculated for (1) full dataset, (2) grains in concordia diagram (same as 1 if all grains have U-Pb and TE), (3) grains below uncertainty threshold (20% on U-Pb ratios), and (4) grains below uncertainty threshold set by power law.\n",
    "\n",
    "The uncertainty threshold is set at a given percent uncertainty for both 238/206 and 207/206 ratios, where points above the threshold are excluded (change % uncertainty threshold in code below, as needed).\n",
    "\n",
    "The power law uncertainty filter (following Chew et al., 2020, Earth Sci. Rev.) is:\n",
    "- 207Pb corrected date uncertainty (2s %) =  8 x (date ^ -0.65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68689be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Define the mafic and pelitic categories based on the discrimination line from Triebold et al., 2012: Cr = 5 * (Nb - 500)\n",
    "\n",
    "# The third subplot only includes uncorrected U-Pb data with 238/206 and 207/206 uncertainties below specified threshold\n",
    "uncertainty_threshold = 20 # Uncertainty threshold in %, excludes U-Pb ratios above this threshold\n",
    "\n",
    "\n",
    "# Drop columns to write new data\n",
    "columns_to_drop = ['MPClassification','MPValue_Triebold2012'] # Columns to drop\n",
    "for column in columns_to_drop:# Check if each column exists before dropping\n",
    "    if column in df.columns:\n",
    "        df = df.drop(columns=[column])\n",
    "        print(f\"Column '{column}' dropped, to be replaced in DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' does not exist in the DataFrame, does not need to be dropped.\")\n",
    "\n",
    "# Using the Triebold 2012 discimination line Cr = 5 * (Nb - 500), classify grains as \"mafic\" or \"pelitic\"\n",
    "line_Triebold2012 = 5 * (Nb - 500)\n",
    "df['Cr_expected'] = 5 * (Nb - 500) # For a given measured Nb, calculate Cr value at discrimination line\n",
    "df['MPClassification'] = np.select(\n",
    "    [\n",
    "        df['Cr_expected'] > Cr,\n",
    "        df['Cr_expected'] < Cr,\n",
    "        pd.isnull(df['Cr_expected'])\n",
    "    ],\n",
    "    [\n",
    "        'pelitic',\n",
    "        'mafic',\n",
    "        'NoProtolith'\n",
    "    ],\n",
    "    default='NoProtolith'\n",
    ")\n",
    "print('\\n',df['MPClassification'].value_counts())\n",
    "MPValue_Triebold2012 = (5 * (Nb - 500)) - Cr # Mafic if > 0, pelitic if < 0\n",
    "df['MPValue_Triebold2012'] = MPValue_Triebold2012\n",
    "\n",
    "\n",
    "# Count number of grains in each class\n",
    "mafic_points = (df['MPClassification'] == 'mafic').sum()\n",
    "pelitic_points = (df['MPClassification'] == 'pelitic').sum()\n",
    "total_points = mafic_points + pelitic_points\n",
    "print(f\"Number of points with 'MPClassification' = 'mafic': {mafic_points}\")\n",
    "print(f\"Number of points with 'MPClassification' = 'pelitic': {pelitic_points}\")\n",
    "print(f\"Total number of points: {total_points}\")\n",
    "\n",
    "\n",
    "# Count number of mafic, pelitic, NoTE points in concordia diagram\n",
    "# Totals may differ if not all grains have U-Pb and TE data\n",
    "mafic_concordia_points = (df['MPClassification'] == 'mafic') & (~pd.Series(Xs386).isna()) & (~pd.Series(Ys76).isna())\n",
    "mafic_concordia_points_sum = mafic_concordia_points.sum()\n",
    "pelitic_concordia_points = (df['MPClassification'] == 'pelitic') & (~pd.Series(Xs386).isna()) & (~pd.Series(Ys76).isna())\n",
    "pelitic_concordia_points_sum = pelitic_concordia_points.sum()\n",
    "NoTREE_concordia_points = (df['MPClassification'] == 'NoProtolith') & (~pd.Series(Xs386).isna()) & (~pd.Series(Ys76).isna())\n",
    "NoTREE_concordia_points_sum = NoTREE_concordia_points.sum()\n",
    "total_concordia = mafic_concordia_points_sum + pelitic_concordia_points_sum + NoTREE_concordia_points_sum\n",
    "#total_concordia2 = np.count_nonzero(~np.isnan(Xs386)) # number of U-Pb points not NaN, should be same as total_concordia\n",
    "print(\"\\nMafic points in concordia diagram:\", mafic_concordia_points.sum())\n",
    "print(\"Pelitic points in concordia diagram:\", pelitic_concordia_points.sum())\n",
    "print('NoTE points in concordia diagram:', NoTREE_concordia_points.sum())\n",
    "print('Total points in concordia diagram:', total_concordia)\n",
    "\n",
    "\n",
    "# Count number of mafic, pelitic, NoTREE points in concordia diagram BELOW uncertainty threshold\n",
    "# Uncertainty threshold mask: Boolean indexing to NOT select points with uncertainties greater than the uncertainty threshold (i.e., 20%)\n",
    "uncertainty_mask = ~(XsErrPerc > uncertainty_threshold) & ~(YsErrPerc > uncertainty_threshold) & (~pd.Series(Xs386).isna()) & (~pd.Series(Ys76).isna()) # points below threshold and not NaN\n",
    "uncertainty_mask_sum = uncertainty_mask.sum() # number of points below uncertainty threshold\n",
    "uncertainty_nonmask_sum = len(uncertainty_mask) - uncertainty_mask.sum() # number of points above uncertainty threshold\n",
    "\n",
    "mafic_concordia_points_uncertainty = (df['MPClassification'] == 'mafic') & uncertainty_mask\n",
    "mafic_concordia_points_uncertainty_sum = mafic_concordia_points_uncertainty.sum()\n",
    "pelitic_concordia_points_uncertainty = (df['MPClassification'] == 'pelitic') & uncertainty_mask\n",
    "pelitic_concordia_points_uncertainty_sum = pelitic_concordia_points_uncertainty.sum()\n",
    "NoTREE_concordia_points_uncertainty = (df['MPClassification'] == 'NoProtolith') & uncertainty_mask\n",
    "NoTREE_concordia_points_uncertainty_sum = NoTREE_concordia_points_uncertainty.sum()\n",
    "total_concordia_uncertainty = mafic_concordia_points_uncertainty_sum + pelitic_concordia_points_uncertainty_sum + NoTREE_concordia_points_uncertainty_sum\n",
    "\n",
    "print(\"\\nMafic points in concordia diagram below uncertaity threshold:\", mafic_concordia_points_uncertainty_sum)\n",
    "print(\"Pelitic points in concordia diagram below uncertaity threshold:\", pelitic_concordia_points_uncertainty_sum)\n",
    "print(\"NoTE points in concordia diagram below uncertaity threshold:\", NoTREE_concordia_points_uncertainty_sum)\n",
    "print('Total points in concordia diagram below uncertaity threshold:', total_concordia_uncertainty)\n",
    "\n",
    "\n",
    "# Count number of mafic, pelitic, NoTREE points in concordia diagram included in power law filter\n",
    "power_law = (Date207c ** -0.65) * 8 * 100\n",
    "power_law_filter = np.where((Date207c_err_perc < power_law), 'include', 'exclude')\n",
    "powerlaw_mask = (Date207c_err_perc < power_law)\n",
    "powerlaw_mask_sum = powerlaw_mask.sum() # number of points included by power law filter\n",
    "powerlaw_nonmask_sum = len(powerlaw_mask) - powerlaw_mask.sum() # number of points excluded by power law filter\n",
    "\n",
    "mafic_concordia_points_powerlaw = (df['MPClassification'] == 'mafic') & powerlaw_mask\n",
    "mafic_concordia_points_powerlaw_sum = mafic_concordia_points_powerlaw.sum()\n",
    "pelitic_concordia_points_powerlaw = (df['MPClassification'] == 'pelitic') & powerlaw_mask\n",
    "pelitic_concordia_points_powerlaw_sum = pelitic_concordia_points_powerlaw.sum()\n",
    "NoTREE_concordia_points_powerlaw = (df['MPClassification'] == 'NoProtolith') & powerlaw_mask\n",
    "NoTREE_concordia_points_powerlaw_sum = NoTREE_concordia_points_powerlaw.sum()\n",
    "total_concordia_powerlaw = mafic_concordia_points_powerlaw_sum + pelitic_concordia_points_powerlaw_sum + NoTREE_concordia_points_powerlaw_sum\n",
    "\n",
    "print(\"\\nMafic points in concordia diagram included by power law fitlter:\", mafic_concordia_points_powerlaw_sum)\n",
    "print(\"Pelitic points in concordia diagram included by power law filter:\", pelitic_concordia_points_powerlaw_sum)\n",
    "print(\"NoTE points in concordia diagram included by power law filter:\", NoTREE_concordia_points_powerlaw_sum)\n",
    "print('Total points in concordia diagram included by power law filter:', total_concordia_powerlaw)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\nNote: if not all grains have U-Pb and TE, totals may differ')\n",
    "\n",
    "# Calculate the Triebold et al 2007 discrimination line: log10(Cr/Nb) = 0 (Cr=Nb) \n",
    "line_values = np.linspace(0, max(Nb), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to view updated DataFrame\n",
    "\n",
    "# New columns added to right:\n",
    "# 'Cr_expected' - For a given measured Nb, calculate expected Cr value at discrimination line. Measured Cr values above or below determines protolith classification\n",
    "# MPClassification - classified as mafic or pelitic or NoTemp\n",
    "# MPValue_Triebold2012 -  (5 * (Nb - 500)) - Cr ... Mafic if > 0, pelitic if < 0. Used in below plots\n",
    "\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61464d98",
   "metadata": {},
   "source": [
    "## 3.2 Protolith Discrimination Plots\n",
    "The following cell creates 3 subplots: (1) Cr vs Nb plot to discriminate mafic and pelitic sources. Grains are classified as mafic or pelitic following the Triebold et al., 2012 line. (2) Uncorrected U-Pb data on Tera-Wasserburg diagram. Analyses are colored by mafic/pelitic/NoTE classification. The concordia date markers are defined in [Section 1](#ConcordiaPoints). (3) Subplot 2 only U-Pb points are filtered by the power law filter set in [Section 3](#UPbUncertainty) (after Chew et al, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c502ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "print('\\n\\033[1mNote: Number mafic, pelitic points may differ between plots due to grains having only U-Pb or TE data\\033[0m\\nTotals reflect number of points with TE and U-Pb in respective plot')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(8, 15))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25) # adjust spacing between subplots\n",
    "\n",
    "### Plot in subplots\n",
    "### Subplot 1\n",
    "\n",
    "axes[0].scatter(Nb[(df['MPClassification'] == 'mafic')], Cr[(df['MPClassification'] == 'mafic')], s=25, color='green', edgecolor='black', linewidth=0.5, label=f'Mafic (n={mafic_points}/{total_points})')\n",
    "axes[0].scatter(Nb[(df['MPClassification'] == 'pelitic')], Cr[(df['MPClassification'] == 'pelitic')], s=25, color='orange', edgecolor='black', linewidth=0.5, label=f'Pelitic (n={pelitic_points}/{total_points})')\n",
    "\n",
    "# Plot the discrimination field lines\n",
    "axes[0].plot(Nb, line_Triebold2012, color='black', linestyle='-', label='Cr = 5 * (Nb - 500)\\nTriebold et al., 2012')\n",
    "axes[0].axvline(x=800, color='black', linestyle='--', label='Cr = 800\\nMeinhold et al., 2008')\n",
    "axes[0].plot(line_values, line_values, linestyle='-.', color='black', label='Cr = Nb\\nTriebold et al., 2007')\n",
    "\n",
    "# Customize the plot\n",
    "#plt.title('Mafic vs Pelitic Protoliths')\n",
    "axes[0].set_xlabel('Nb (ppm)')\n",
    "axes[0].set_ylabel('Cr (ppm)')\n",
    "axes[0].set_title('Cr vs Nb Discrimination Diagram')\n",
    "axes[0].legend()\n",
    "\n",
    "# Set the axis limits\n",
    "# Calculate the rounded-up maximum value for both axes\n",
    "max_Nb_rounded = np.ceil(np.max(Nb) / 100) * 100\n",
    "max_Cr_rounded = np.ceil(np.max(Cr) / 100) * 100\n",
    "axes[0].set_xlim(0, max_Nb_rounded)\n",
    "axes[0].set_ylim(0, max_Cr_rounded)\n",
    "\n",
    "\n",
    "### Subplot 2\n",
    "# Plot concordia diagram in Tera-Wasserburg space\n",
    "axes[1].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='black', facecolors='black', linewidth=0.5, zorder=2, label='Concordia Points')  # Mark specified points along concordia in black\n",
    "axes[1].plot(X86, Y76, color='red', zorder=1, label='Concordia Curve')  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6):\n",
    "    axes[1].text(X86tMyr[i] - 0.35, Y76tMyr[i] - 0.04, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Scatter plot for mafic points\n",
    "axes[1].scatter(Xs386[df['MPClassification'] == 'mafic'], Ys76[df['MPClassification'] == 'mafic'],\n",
    "                label='Mafic', s=25, c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[1].scatter(Xs386[df['MPClassification'] == 'pelitic'], Ys76[df['MPClassification'] == 'pelitic'],\n",
    "                label='Pelitic', s=25, c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "# Scatter plot for \"No TE\" points\n",
    "axes[1].scatter(Xs386[df['MPClassification'] == 'NoProtolith'], Ys76[df['MPClassification'] == 'NoProtolith'],\n",
    "                label='No TE', s=15, c='white', edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "axes[1].set_xlabel(r'$^{238}$U/$^{206}$Pb')\n",
    "axes[1].set_ylabel(r'$^{207}$Pb/$^{206}$Pb')\n",
    "axes[1].set_title('Uncorrected U-Pb Data')\n",
    "legend_labels = {'mafic': f'Mafic (n={mafic_concordia_points_sum}/{total_concordia})', \n",
    "                 'pelitic': f'Pelitic (n={pelitic_concordia_points_sum}/{total_concordia})', \n",
    "                 'No TREE': f'No TE (n={NoTREE_concordia_points_sum}/{total_concordia})'}\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=6, markeredgecolor='black', label=label)\n",
    "    for color, label in zip(['green', 'orange', 'white'], legend_labels.values())\n",
    "]\n",
    "axes[1].legend(handles=legend_handles, loc='upper right')\n",
    "\n",
    "# Set x and y-axis limits for the second subplot\n",
    "axes[1].set_xlim([-5, 90])  # Replace with your desired values\n",
    "axes[1].set_ylim([-0.05, 2])  # Replace with your desired values\n",
    "\n",
    "\n",
    "### Subplot 3\n",
    "# Power law filter applied\n",
    "axes[2].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='black', facecolors='black', linewidth=0.5, zorder=2)  # Mark specified points along concordia in black\n",
    "axes[2].plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6): # plot text labels on concordia\n",
    "    axes[2].text(X86tMyr[i]- 0.35, Y76tMyr[i] - 0.04, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Scatter plot for mafic points included by filter\n",
    "axes[2].scatter(Xs386[(powerlaw_mask) & (df['MPClassification'] == 'mafic')], Ys76[(powerlaw_mask) & (df['MPClassification'] == 'mafic')],\n",
    "                label='mafic', s=25, c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points included by filter\n",
    "axes[2].scatter(Xs386[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')], Ys76[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')],\n",
    "                label='pelitic', s=25, c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "# Scatter plot for \"No TREE\" points included by filter\n",
    "axes[2].scatter(Xs386[(powerlaw_mask) & (df['MPClassification'] == 'NoProtolith')], Ys76[(powerlaw_mask) & (df['MPClassification'] == 'NoProtolith')],\n",
    "                label='No TE', s=15, c='white', edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "\n",
    "axes[2].set_xlim([-5, 90])  # Replace with desired values\n",
    "axes[2].set_ylim([-0.05, 1.2])  # Replace with desired values\n",
    "axes[2].set_xlabel(r'$^{238}$U/$^{206}$Pb')\n",
    "axes[2].set_ylabel(r'$^{207}$Pb/$^{206}$Pb')\n",
    "axes[2].set_title(f'Uncorrected U-Pb Data with Power Law Filter')\n",
    "legend_labels = {'mafic': f'Mafic (n={mafic_concordia_points_powerlaw_sum}/{total_concordia_powerlaw})', \n",
    "                 'pelitic': f'Pelitic (n={pelitic_concordia_points_powerlaw_sum}/{total_concordia_powerlaw})', \n",
    "                 'No TREE': f'No TE (n={NoTREE_concordia_points_powerlaw_sum}/{total_concordia_powerlaw})'}\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=6, markeredgecolor='black', label=label)\n",
    "    for color, label in zip(['green', 'orange', 'white'], legend_labels.values())\n",
    "]\n",
    "axes[2].legend(handles=legend_handles, loc='upper right')\n",
    "\n",
    "axes[2].grid(False)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"MaficPelitic_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d422fe",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "# 4. Zr-in-Rutile Thermometry\n",
    "\n",
    "The following section uses the zirconium concentration data to explore rutile temperature. Temperatures are calculated for 3 different Zr-in-rutile formulations (Zack et al., 2004; Watson et al., 2006; Kohn, 2020). The temperatures calculated with the Kohn (2020) equation are used in subsequent plots.\n",
    "\n",
    "Update the Zr concentration variable with the correct column name in the DataFrame ('Zr' in [Section 1](#DefineVariables)).\n",
    "\n",
    "## 4.1 Calculate Zr-in-rutile temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial Zr-in-rutile temperature calculations\n",
    "# Run once\n",
    "# Appends variabes to DataFrame\n",
    "\n",
    "Pressure = 13000 # pressure in bars, Storey and Pereira 2023 recommend 13000 bars detritals\n",
    "PressureErr = 5000 # to estimate uncertainty, Storey and Pereira 2023 recommend 5000 bars\n",
    "R = 8.3144 # Gas constant, R\n",
    "\n",
    "KohnTempC = (71360+(0.378*Pressure)-(0.13*Zr))/(130.66-(R*np.log(Zr))) - 273.15 # Kohn 2020 eqn 13. in Celcius\n",
    "KohnTempC_err = KohnTempC - ((71360+(0.378*(Pressure-PressureErr))-(0.13*Zr))/(130.66-(R*np.log(Zr))) - 273.15)\n",
    "WatsonTempC = (4470./(7.36 - logZr))-273; # Watson et al 2006 temperature formulation. in Celcius\n",
    "ZackTempC = 127.8 * logZr - 10; # Zack et al 2004 temperature formulation. in Celcius\n",
    "\n",
    "\n",
    "### Write variables into DataFrame\n",
    "df['Pressure_(kbar)'] = Pressure\n",
    "df['PressureErr_(kbar)'] = PressureErr\n",
    "df['KohnTempC'] = KohnTempC\n",
    "df['KohnTempC_err'] = KohnTempC_err\n",
    "df['TClassification'] = np.nan # Create a new column 'Tclass' and initialize with default value\n",
    "df['WatsonTempC'] = WatsonTempC\n",
    "df['ZackTempC'] = ZackTempC\n",
    "\n",
    "\n",
    "# Classify into 'moderate' (350-600 C) and 'high' (> 600 C) temperature groups  \n",
    "df.loc[(KohnTempC >= 350) & (KohnTempC <= 600), 'TClassification'] = 'moderate'\n",
    "df.loc[KohnTempC > 600, 'TClassification'] = 'high'\n",
    "    \n",
    "\n",
    "print('\\nFirst 10 rows of temperatures (°C) calculated with Kohn 2020 eqn:\\n', KohnTempC.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to display the combined DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(10)  # display first 10 rows of the combined DataFrame\n",
    "#df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb008585",
   "metadata": {},
   "source": [
    "<a id='Section4plot1'></a>\n",
    "## 4.2 Zr-in-Rutile Temperature on Concordia Diagram\n",
    "The next cell plots the Zr-in-rutile temperature on concordia diagrams (uncorrected U-Pb data). Subplot 1 is all uncorrected U-Pb data on Tera-Wasserburg diagram; subplot 2 excludes points above the power law threshold set in [Section 3](#UPbUncertainty). The concordia age markers are defined in [Section 1](#ConcordiaPoints).\n",
    "\n",
    "Note: Axis limits are set below and should be adjusted. U-Pb analyses displayed as points not error ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12aead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Zr-in-rutile temperatures on Tera-Wasserburg diagram\n",
    "\n",
    "total_concordia = np.count_nonzero(~np.isnan(Xs386)) # number of U-Pb points not NaN\n",
    "\n",
    "# Plot in Tera-Wasserburg space\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "axes[0].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='black', facecolors='black', linewidth=0.5, zorder=2)  # Mark specified points along concordia in black\n",
    "axes[0].plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6): # plot text labels on concordia\n",
    "    axes[0].text(X86tMyr[i] - 0.75, Y76tMyr[i] - 0.075, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Scatter plot of uncorrected U-Pb points\n",
    "scatter1 = axes[0].scatter(Xs386, Ys76, c=KohnTempC, cmap=cm.roma_r, label=f'All uncorrected analyses\\n(n={total_concordia})', edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "plt.xlabel(r'$^{238}$U/$^{206}$Pb', fontsize=12)\n",
    "plt.ylabel(r'$^{207}$Pb/$^{206}$Pb', fontsize=12)\n",
    "\n",
    "# Add colorbar\n",
    "colorbar1 = fig.colorbar(scatter1, ax=axes[0])\n",
    "colorbar1.set_label('Temperature (°C)', rotation=270, labelpad=15)\n",
    "\n",
    "# Set x and y-axis limits\n",
    "axes[0].set_xlim([-5, 90])  # Replace with desired values\n",
    "axes[0].set_ylim([-0.05, 2])  # Replace with desired values\n",
    "axes[0].legend()\n",
    "axes[0].grid(False)\n",
    "\n",
    "\n",
    "# Subplot 2, uncertainty threshold applied (power law)\n",
    "axes[1].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='black', facecolors='black', linewidth=0.5, zorder=2)  # Mark specified points along concordia in black\n",
    "axes[1].plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6): # plot text labels on concordia\n",
    "    axes[1].text(X86tMyr[i] - 0.35, Y76tMyr[i] - 0.04, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Plot only the points below uncertainty threshold (power law)\n",
    "scatter2 = axes[1].scatter(Xs386[powerlaw_mask], Ys76[powerlaw_mask], c=KohnTempC[powerlaw_mask], cmap=cm.roma_r,  \n",
    "            label=f'Uncorrected analyses \\nincluded by power law filter', edgecolors='black', \n",
    "            linewidth=0.5, zorder=3)\n",
    "axes[1].scatter(Xs386[(powerlaw_mask) & (df['MPClassification'] == 'NoProtolith')], Ys76[(powerlaw_mask) & (df['MPClassification'] == 'NoProtolith')],\n",
    "                label='No TE', s=15, c='white', edgecolors='black', linewidth=0.5, zorder=2)\n",
    "\n",
    "\n",
    "colorbar2 = fig.colorbar(scatter2, ax=axes[1])\n",
    "colorbar2.set_label('Temperature (°C)', rotation=270, labelpad=15)\n",
    "legend_labels = {'No TREE': f'No TE (n={NoTREE_concordia_points_powerlaw_sum}/{total_concordia_powerlaw})'}\n",
    "\n",
    "axes[1].set_xlim([-5, 90])  # Replace with desired values\n",
    "axes[1].set_ylim([-0.05, 1.2])  # Replace with desired values\n",
    "axes[1].legend()\n",
    "axes[1].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"ZrTemp_concordia_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad18c4",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "# 5. Low U Rutile\n",
    "\n",
    "This section explores low U rutile within the dataset. To run this section, the DataFrame must include \"percent concordance\" which is calculated in the 207Pb correction section of the Common Pb Correction notebook.\n",
    "\n",
    "\n",
    "## 5.1 Zr-in-rutile temperature vs U concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zr-in-rutile temperature vs U concentration\n",
    "\n",
    "filter3 = ~( U.isna() | KohnTempC.isna() | df['MPClassification'].isna() ) # filter out values = NaN\n",
    "\n",
    "# Define the colors based on the mafic-pelitic classification of Triebold et al. 2012\n",
    "MPcolors3 = ['green' if y < 0 else 'orange' for y in MPValue_Triebold2012[filter3]]\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(U[filter3], KohnTempC[filter3], c=MPcolors3, edgecolors='black', linewidth=0.5)\n",
    "plt.xscale('log')\n",
    "plt.axvline(x=4, color='black', linestyle='--', linewidth = 1, label='x=4') # Vertical line at U = 4 ppm\n",
    "y1 = 500\n",
    "y2 = 750\n",
    "plt.axhline(y1, color='black', linestyle=':', linewidth = 1, label='y=500')\n",
    "plt.axhline(y2, color='black', linestyle=':', linewidth = 1,label='y=750')\n",
    "# Adding text labels just above the horizontal lines\n",
    "plt.text(5e-3, y2 + 10, 'Granulite', color='black', fontsize=10, va='bottom')\n",
    "plt.text(30, y1 + 10, 'Amphibolite/\\nEclogite', color='black', fontsize=10, va='bottom')\n",
    "plt.text(30, y1 - 75, 'Greenschist/\\nBlueschist', color='black', fontsize=10, va='bottom')\n",
    "plt.text(3.5, 785, '4 ppm', rotation='vertical', va='bottom', ha='right', color='black', fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "# Adding colorbar\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.set_label('U (ppm)')\n",
    "\n",
    "# Labeling axes\n",
    "plt.xlabel('U (ppm)')\n",
    "plt.ylabel('Zr-in-rutile Temperature (°C)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68685b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"ZrvsU_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        plt.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c15394",
   "metadata": {},
   "source": [
    "## 5.2 Concordia Diagram Colored by U Concentration\n",
    "Subplots of concordia diagrams colored by U concentration. The second subplot uses the power law filter defined in [Section 3](#UPbUncertainty) and applied here with the same conditions. The concordia age markers are defined in [Section 1](#ConcordiaPoints).\n",
    "\n",
    "Note: U-Pb analyses displayed as points not error ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concordia diagram colored by U concentration\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "### Plot Zr-in-rutile temperatures on Tera-Wasserburg diagram\n",
    "palette = 'copper_r'#'coolwarm'\n",
    "\n",
    "total_concordia = np.count_nonzero(~np.isnan(Xs386)) # number of U-Pb points not NaN\n",
    "\n",
    "\n",
    "# Plot in Tera-Wasserburg space\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "axes[0].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='red', facecolors='red', linewidth=0.5, zorder=2)  # Mark specified points along concordia in black\n",
    "axes[0].plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6): # plot text labels on concordia\n",
    "    axes[0].text(X86tMyr[i] - 0.75, Y76tMyr[i] - 0.075, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Scatter plot of uncorrected U-Pb points\n",
    "#norm = mcolors.LogNorm(vmin=1e-2, vmax=10000)\n",
    "scatter1 = axes[0].scatter(Xs386, Ys76, c=U, cmap=palette, norm=mcolors.LogNorm(), label=f'All uncorrected analyses\\n(n={total_concordia})', edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "# Add colorbar with log scale\n",
    "colorbar1 = fig.colorbar(scatter1, ax=axes[0])  \n",
    "colorbar1.set_label('U (ppm)', rotation=270, labelpad=15)\n",
    "\n",
    "# Set labels\n",
    "axes[0].set_xlabel(r'$^{238}$U/$^{206}$Pb', fontsize=12)\n",
    "axes[0].set_ylabel(r'$^{207}$Pb/$^{206}$Pb', fontsize=12)\n",
    "axes[0].set_title(r'Tera-Wasserburg Diagram of Uncorrected U-Pb Analyses Colored by U Concentration')\n",
    "\n",
    "# Set x and y-axis limits\n",
    "axes[0].set_xlim([-5, 90])  # Replace with desired values\n",
    "axes[0].set_ylim([-0.05, 2])  # Replace with desired values\n",
    "axes[0].legend()\n",
    "axes[0].grid(False)\n",
    "\n",
    "\n",
    "# Subplot 2, uncertainty threshold applied (power law)\n",
    "axes[1].scatter(X86tMyr, Y76tMyr, s=10, edgecolors='red', facecolors='red', linewidth=0.5, zorder=2)  # Mark specified points along concordia in black\n",
    "axes[1].plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "for i, age in enumerate(tMyr / 1e6): # plot text labels on concordia\n",
    "    axes[1].text(X86tMyr[i] - 0.35, Y76tMyr[i] - 0.04, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "# Plot only the points below uncertainty threshold (power law)\n",
    "scatter2 = axes[1].scatter(Xs386[powerlaw_mask], Ys76[powerlaw_mask], c=U[powerlaw_mask], cmap=palette, norm=mcolors.LogNorm(),  \n",
    "            label=f'Uncorrected analyses included \\nin power law filter\\n(n={powerlaw_mask_sum}/{total_concordia})', edgecolors='black', \n",
    "            linewidth=0.5, zorder=3)\n",
    "\n",
    "colorbar2 = fig.colorbar(scatter2, ax=axes[1])\n",
    "colorbar2.set_label('U (ppm)', rotation=270, labelpad=15)\n",
    "\n",
    "# Set labels\n",
    "axes[1].set_xlabel(r'$^{238}$U/$^{206}$Pb', fontsize=12)\n",
    "axes[1].set_ylabel(r'$^{207}$Pb/$^{206}$Pb', fontsize=12)\n",
    "axes[1].set_title(r'Power Law Filter Applied')\n",
    "\n",
    "# Set axis limits\n",
    "axes[1].set_xlim([-5, 90])  # Replace with desired values\n",
    "axes[1].set_ylim([-0.05, 1.2])  # Replace with desired values\n",
    "axes[1].legend()\n",
    "axes[1].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a903c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"TW_by_U_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64161222",
   "metadata": {},
   "source": [
    "## 5.3 Comparison of U concentration and concordance\n",
    "\n",
    "### U concentration and concordance with power law filter\n",
    "The power law filter is applied to the U-Pb data. The variables for percent concordance, U-Pb ratios and corrected date are defined in [Section 1](#DefineVariables). The concordia age markers are defined in [Section 1](#ConcordiaPoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zr-in-rutile temperatures versus U contents\n",
    "\n",
    "cmap = 'PiYG' \n",
    "\n",
    "# Determine the quadrant for each point\n",
    "df['Quadrant'] = np.nan\n",
    "df.loc[(U >= 4), 'Quadrant'] = 1\n",
    "df.loc[(U < 4), 'Quadrant'] = 2\n",
    "#df.loc[(U <= 4) & (PercConc <= 40), 'Quadrant'] = 3\n",
    "#df.loc[(U <= 4) & (PercConc > 40), 'Quadrant'] = 4\n",
    "\n",
    "print(f'Plot replicated with U-Pb power law filter applied to all subplots')\n",
    "\n",
    "### Subplot 1: Define quadrants based on U and Concordance \n",
    "# Scatter plot spanning two columns in the first row\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.subplot(2, 2, 1)\n",
    "scatter1 = plt.scatter(PercConc[powerlaw_mask], U[powerlaw_mask], c=df['Quadrant'][powerlaw_mask], s=50, \n",
    "                       edgecolors='black', linewidth=0.5, cmap=cmap)\n",
    "plt.axhline(4, color='black', linestyle='--', linewidth=1, label='U = 4 ppm')\n",
    "y1 = 5\n",
    "x1 = -2\n",
    "plt.text(x1, y1, '4 ppm', rotation='vertical',color='black', fontsize=10, va='bottom')\n",
    "\n",
    "#plt.axvline(40, color='black', linestyle='--', linewidth=1, label='PercConc = 40%')\n",
    "plt.xlabel('Stacey-Kramers Concordance (%)')\n",
    "plt.ylabel('U (ppm)')\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "### Subplot 2\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "# Plot concordia diagram in Tera-Wasserburg space\n",
    "plt.scatter(X86tMyr, Y76tMyr, s=10, edgecolors='red', facecolors='red', linewidth=0.5, zorder=2, label='Concordia Points')  # Mark specified points along concordia in black\n",
    "plt.plot(X86, Y76, color='red', zorder=1, label='Concordia Curve')  # Plot concordia\n",
    "\n",
    "\n",
    "# Mask NaN values in the Quadrant column or percent concordant values of NaN or 0.0\n",
    "nan_mask = df['Quadrant'].isna() | PercConc.isna() | PercConc == 0\n",
    "\n",
    "# Scatter plot for non-NaN values of Quadrants\n",
    "plt.scatter(i386[~nan_mask & powerlaw_mask], i76[~nan_mask & powerlaw_mask], c=df['Quadrant'][~nan_mask & powerlaw_mask], \n",
    "            cmap=cmap, s=50, edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "# Scatter plot for NaN values (white points with black edge)\n",
    "plt.scatter(i386[nan_mask], i76[nan_mask], color='white', edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "plt.xlabel(r'$^{238}$U/$^{206}$Pb', fontsize=12)\n",
    "plt.ylabel(r'$^{207}$Pb/$^{206}$Pb', fontsize=12)\n",
    "# Set x and y-axis limits for the second subplot\n",
    "plt.xlim([-3, 90])  # Replace with your desired values\n",
    "plt.ylim([0, 1])  # Replace with your desired values\n",
    "\n",
    "\n",
    "# Subplot 3: U versus Date\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "plt.scatter(Date207c[~nan_mask & powerlaw_mask], U[~nan_mask & powerlaw_mask], \n",
    "            c=df['Quadrant'][~nan_mask & powerlaw_mask], cmap=cmap, s=50, edgecolors='black', linewidth=0.5, zorder=3)\n",
    "\n",
    "plt.axhline(4, color='black', linestyle='--', linewidth=1, label='U = 4 ppm')\n",
    "y1 = 6\n",
    "x1 = 1750\n",
    "plt.text(x1, y1, '4 ppm', color='black', fontsize=10, va='bottom')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Corrected Date (Ma)')\n",
    "plt.ylabel('U (ppm)')\n",
    "plt.xlim([0, 2000])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd40590",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"LowU_PowerLawFilter_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        plt.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62595f",
   "metadata": {},
   "source": [
    "<a id='Section6'></a>\n",
    "# 6. Evaluating Potential Bias\n",
    "The following plots are intended to evaluate potential bias in U-Pb data rejection during data reduction and in power law filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caad4ac",
   "metadata": {},
   "source": [
    "## 6.1 Protolith vs Corrected Date\n",
    "The following plot is inteded to evaluate potential bias in the power law filter.\n",
    "\n",
    "The cell below plots the mafic-pelitic classification (Triebold et al., 2012 discrimination field) versus corrected U-Pb date. If needed, update the corrected date variable with the correct column name in the DataFrame ('Date207c' in [Section 1](#DefineVariables)). Cannot be run without running above cells in [Section 3](#Section3). The power law filter is set above, as well.\n",
    "\n",
    "The Cr and Nb values are transformed around Cr = 5*(Nb-500), so that above 1 is mafic and below 1 is pelitic. This calculation is performed in [Section 3.1](#Section3). The absolute values along y-axis do not have much meaning, but the plots provide a sense for how protoliths are distributed across date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db753c15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot Mafic-Pelitic vs Corrected Date\n",
    "# y-axis is essentially distance of point from Triebold 2012 discrimination line. Defined as 'MPValue_Triebold2012' in Section 3 cell 1.\n",
    "\n",
    "filter1 = ~( (Date207c == 0) | Date207c.isna() ) # filter out values = 0 or NaN\n",
    "\n",
    "# Number of points in each subplot\n",
    "mafic_points1 = len(Date207c[(filter1) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points1 = len(Date207c[(filter1) & (df['MPClassification'] == 'pelitic')])\n",
    "mafic_points2 = len(Date207c[(powerlaw_mask) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points2 = len(Date207c[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')])\n",
    "mafic_points3 = len(Date207c[(~powerlaw_mask) & (filter1) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points3 = len(Date207c[(~powerlaw_mask) & (filter1) & (df['MPClassification'] == 'pelitic')])\n",
    "\n",
    "\n",
    "### Subplot 1\n",
    "# plot protolith by date\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(8, 15))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5) # adjust spacing between subplots\n",
    "\n",
    "# Scatter plot for mafic points\n",
    "axes[0].scatter(Date207c[(filter1) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(filter1) & (df['MPClassification'] == 'mafic')],\n",
    "                label = f'Mafic (n={mafic_points1})', \n",
    "                s=25, c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[0].scatter(Date207c[(filter1) & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(filter1) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points1})', \n",
    "                s=25, c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "axes[0].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlim(0, 1000)\n",
    "axes[0].set_xlabel('Corrected Date (Ma)')\n",
    "axes[0].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[0].set_title('A. Protolith vs Corrected Date (Unfiltered)')\n",
    "axes[0].legend()\n",
    "\n",
    "### Subplot 2\n",
    "# Scatter plot for mafic points\n",
    "axes[1].scatter(Date207c[(powerlaw_mask) & (filter1) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(powerlaw_mask) & (filter1) & (df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points2})', \n",
    "                s=25, c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[1].scatter(Date207c[(powerlaw_mask) & (filter1) & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(powerlaw_mask) & (filter1) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points2})', \n",
    "                s=25, c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "\n",
    "axes[1].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlim(0, 1000)\n",
    "axes[1].set_xlabel('Corrected Date (Ma)')\n",
    "axes[1].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[1].set_title(f'B. Protolith vs Corrected Dates (power law filter applied)')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "### Subplot 3\n",
    "# Scatter plot for mafic points\n",
    "axes[2].scatter(Date207c[(~powerlaw_mask) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(~powerlaw_mask) & (df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points3})', \n",
    "                s=25, c='green', marker='x', zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[2].scatter(Date207c[(~powerlaw_mask)  & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(~powerlaw_mask) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points3})', \n",
    "                s=25, c='orange', marker='x', zorder=4)\n",
    "\n",
    "\n",
    "axes[2].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].set_xlim(0, 1000)\n",
    "axes[2].set_ylim(8e-4, 3e4)\n",
    "axes[2].set_xlabel('Corrected Date (Ma)')\n",
    "axes[2].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[2].set_title('C. Points in A excluded from B')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38231da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"MaficPeliticVsDate_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec4cc4",
   "metadata": {},
   "source": [
    "## 6.2 Protolith vs Zr-in-rutile temperature\n",
    "The following plots are intended to evaluate potential bias in the U-Pb data rejection and power law filtering.\n",
    "\n",
    "The cell below plots the mafic-pelitic classification (Triebold et al., 2012 discrimination field) versus Zr-in-rutile temperature. \n",
    "\n",
    "The Cr and Nb values are transformed around Cr = 5*(Nb-500), so that above 1 is mafic and below 1 is pelitic. This calculation is performed in [Section 3.1](#Section3). The absolute values along y-axis do not have much meaning, but the plots provide a sense for how protoliths are distributed across date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97834f9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot Mafic-Pelitic vs Corrected Date\n",
    "# y-axis is essentially distance of point from Triebold 2012 discrimination line. Defined as 'MPValue_Triebold2012' in Section 3 cell 1.\n",
    "# no uncertainty filter applied\n",
    "\n",
    "filter1 = ~( (Date207c == 0) | Date207c.isna() ) # filter out if no U-Pb data (values = 0 or NaN)\n",
    "\n",
    "# Number of points in each subplot\n",
    "mafic_points1 = len(KohnTempC[(df['MPClassification'] == 'mafic')])\n",
    "pelitic_points1 = len(KohnTempC[(df['MPClassification'] == 'pelitic')])\n",
    "mafic_points2 = len(KohnTempC[(filter1) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points2 = len(KohnTempC[(filter1) & (df['MPClassification'] == 'pelitic')])\n",
    "mafic_points3 = len(KohnTempC[(powerlaw_mask) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points3 = len(KohnTempC[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')])\n",
    "mafic_points4 = len(KohnTempC[(~powerlaw_mask) & (df['MPClassification'] == 'mafic')])\n",
    "pelitic_points4 = len(KohnTempC[(~powerlaw_mask)  & (df['MPClassification'] == 'pelitic')])\n",
    "\n",
    "\n",
    "### Subplot 1\n",
    "# plot Protolith by date\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(8, 20))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5) # adjust spacing between subplots\n",
    "\n",
    "# Scatter plot for mafic points\n",
    "axes[0].scatter(KohnTempC[(df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points1})', c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[0].scatter(KohnTempC[(df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points1})', c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "\n",
    "axes[0].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlim(300, 900)\n",
    "axes[0].set_xlabel('Temperature (°C)')\n",
    "axes[0].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[0].set_title('A. Protolith vs Temperature')\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "### Subplot 2\n",
    "# Protolith vs Temperature for points with U-Pb\n",
    "# Scatter plot for mafic points\n",
    "axes[1].scatter(KohnTempC[(filter1) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(filter1) & (df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points2})', c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[1].scatter(KohnTempC[(filter1) & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(filter1) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points2})', c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "\n",
    "axes[1].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlim(300, 900)\n",
    "axes[1].set_xlabel('Temperature (°C)')\n",
    "axes[1].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[1].set_title(f'B. Protolith vs Temperature (only points with TE and U-Pb)')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "### Subplot 3\n",
    "# Protolith vs Temperature for points with U-Pb below uncertainty threshold (power law)\n",
    "# Scatter plot for mafic points\n",
    "axes[2].scatter(KohnTempC[(powerlaw_mask) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(powerlaw_mask) & (df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points3})', c='green', edgecolors='black', linewidth=0.5, zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[2].scatter(KohnTempC[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(powerlaw_mask) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points3})', c='orange', edgecolors='black', linewidth=0.5, zorder=4)\n",
    "\n",
    "\n",
    "axes[2].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].set_xlim(300, 900)\n",
    "axes[2].set_ylim(8e-4, 3e4)\n",
    "axes[2].set_xlabel('Temperature (°C)')\n",
    "axes[2].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[2].set_title(f'C. Protolith vs Temperature (only points with TE and included by power law filter)')\n",
    "axes[2].legend()\n",
    "\n",
    "\n",
    "### Subplot 4\n",
    "# Protolith vs Temperature for points with U-Pb below uncertainty threshold  (power law)\n",
    "# Scatter plot for mafic points\n",
    "axes[3].scatter(KohnTempC[(~powerlaw_mask) & (df['MPClassification'] == 'mafic')], (line_Triebold2012/Cr)[(~powerlaw_mask) & (df['MPClassification'] == 'mafic')],\n",
    "                label=f'Mafic (n={mafic_points4})', s=25, c='green', marker='x', zorder=5)\n",
    "\n",
    "# Scatter plot for pelitic points\n",
    "axes[3].scatter(KohnTempC[(~powerlaw_mask) & (df['MPClassification'] == 'pelitic')], (line_Triebold2012/Cr)[(~powerlaw_mask) & (df['MPClassification'] == 'pelitic')],\n",
    "                label=f'Pelitic (n={pelitic_points4})', s=25, c='orange', marker='x', zorder=4)\n",
    "\n",
    "\n",
    "axes[3].axhline(y=1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[3].set_yscale('log')\n",
    "axes[3].set_xlim(300, 900)\n",
    "axes[3].set_ylim(8e-4, 3e4)\n",
    "axes[3].set_xlabel('Temperature (°C)')\n",
    "axes[3].set_ylabel('Mafic vs. Pelitic')\n",
    "axes[3].set_title(f'D. Points from A excluded in C')\n",
    "axes[3].legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"ProtolithvsTemp_UPb_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9efe9",
   "metadata": {},
   "source": [
    "## 6.3 Zr-in-Rutile Temperature vs. Corrected Date -- Colored by Protolith \n",
    "The next cell plots the Zr-in-rutile temperature versus Pb-corrected date with points colored by mafic-pelitic classification. The corrected date variable is set as 'Date207c' in [Section 1](#DefineVariables). The power law filter is defined in [Section 3](#UPbUncertainty) and applied here with the same conditions.\n",
    "\n",
    "Note: X-axis limit is set below and should be adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cba4f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define Pb corrected age from column in DataFrame\n",
    "# Uses same uncertainty filter ('powerlaw_mask') as defined above\n",
    "\n",
    "# Set data filters  \n",
    "filter2 = ~( (Date207c == 0) | Date207c.isna() | (KohnTempC == 0) | KohnTempC.isna() ) # filter out values = 0 or NaN\n",
    "filter2_MPValue_Triebold2012 = MPValue_Triebold2012[filter2]\n",
    "powerlaw_mask_MPValue_Triebold2012 = filter2_MPValue_Triebold2012[powerlaw_mask]\n",
    "MPcolors1 = ['green' if y < 0 else 'orange' for y in filter2_MPValue_Triebold2012]\n",
    "MPcolors2 = ['green' if y < 0 else 'orange' for y in powerlaw_mask_MPValue_Triebold2012]\n",
    "print('Mafic is green, pelitic is orange')\n",
    "\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 15))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5) # adjust spacing between subplots\n",
    "\n",
    "\n",
    "### Subplot 1\n",
    "axes[0].scatter(Date207c[filter2], KohnTempC[filter2], c=MPcolors1, \n",
    "                label=f'Analyses with TE\\nand U-Pb (n={total_concordia})', edgecolors = \"black\", linewidth = 0.5)\n",
    "\n",
    "axes[0].set_xlabel('Corrected Date (Ma)')\n",
    "axes[0].set_ylabel('Zr-in-rutile Temperature (°C)')\n",
    "axes[0].set_title('A. Zr-in-rutile Temperature vs Corrected Date')\n",
    "axes[0].set_xlim(0, 1000)\n",
    "axes[0].set_ylim(300, 900)\n",
    "y1 = 600\n",
    "x1 = 800\n",
    "axes[0].axhline(y=y1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[0].text(x1, y1 + 15, 'High Temp.', color='black', fontsize=10, va='bottom')\n",
    "axes[0].text(x1, y1 - 45, 'Moderate Temp.', color='black', fontsize=10, va='bottom')\n",
    "\n",
    "axes[0].legend()\n",
    "\n",
    "### Subplot 2\n",
    "# Subplot uses uncertainty threshold powerlaw_mask defined in above concordia plots of Zr temps\n",
    "axes[1].scatter(Date207c[powerlaw_mask & filter2], KohnTempC[powerlaw_mask & filter2], c=MPcolors2, \n",
    "            label=f'Analyses below uncertainty\\nthreshold (n={powerlaw_mask_sum}/{total_concordia})', edgecolors='black', \n",
    "            linewidth=0.5, zorder=3)\n",
    "\n",
    "axes[1].set_xlim(0, 1000)\n",
    "axes[1].set_ylim(300, 900)\n",
    "axes[1].axhline(y=y1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[1].text(x1, y1 + 15, 'High Temp.', color='black', fontsize=10, va='bottom')\n",
    "axes[1].text(x1, y1 - 45, 'Moderate Temp.', color='black', fontsize=10, va='bottom')\n",
    "\n",
    "\n",
    "\n",
    "axes[1].set_xlabel('Corrected Date (Ma)')\n",
    "axes[1].set_ylabel('Zr-in-rutile Temperature (°C)')\n",
    "axes[1].set_title(f'B. Zr-in-rutile Temperature vs Corrected Date (power law filter applied)')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "### Subplot 3\n",
    "# Subplot uses uncertainty threshold powerlaw_mask defined in above concordia plots of Zr temps\n",
    "axes[2].scatter(Date207c[~powerlaw_mask & filter2], KohnTempC[~powerlaw_mask & filter2], marker='x', c=\"black\",\n",
    "            label=f'Analyses excluded in B', zorder=3)\n",
    "\n",
    "axes[2].set_xlim(0, 1000)\n",
    "axes[2].set_ylim(300, 900)\n",
    "axes[2].axhline(y=y1, color='black', linestyle='--', linewidth=1) # moderate vs high Temp line\n",
    "axes[2].text(x1, y1 + 15, 'High Temp.', color='black', fontsize=10, va='bottom')\n",
    "axes[2].text(x1, y1 - 45, 'Moderate Temp.', color='black', fontsize=10, va='bottom')\n",
    "axes[2].set_xlabel('Corrected Date (Ma)')\n",
    "axes[2].set_ylabel('Zr-in-rutile Temperature (°C)')\n",
    "axes[2].set_title(f'C. Points in A excluded from B')\n",
    "axes[2].legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to save the plot? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"TempVsDate_MPcolor_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9add0b1",
   "metadata": {},
   "source": [
    "<a id='Section7'></a>\n",
    "## 7. Export New DataFrame\n",
    "\n",
    "\n",
    "Throughout the notebook, new columns have been added to the initial dataframe. This section exports the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to view new dataframe\n",
    "# Columns added from protolith, temperature and U-concordance quadrant calcultions (far right)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save to Excel file\n",
    "\n",
    "user_input = input(\"\\033[1mDo you want to export the dataframe? (yes/no): \\033[0m\\n yes/no is case sensitive \\n If yes, will open window to save.\\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path1, \"OutputFile_Rutile_TE_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
