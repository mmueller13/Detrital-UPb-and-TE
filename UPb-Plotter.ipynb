{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7664583b",
   "metadata": {},
   "source": [
    "# <div align=\"center\">UPb-Plotter </div>\n",
    "## <div align=\"center\">Python code for plotting U-Pb data and exploring discordance</div>\n",
    "\n",
    "#### <br><div align=\"center\">Megan Mueller</div>\n",
    "##### <div align=\"center\">Please cite the accompanying article published in Geochronology:</div>\n",
    "<div align=\"center\">Mueller et al., 2024, https://doi.org/10.5194/gchron-6-265-2024 </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f79948",
   "metadata": {},
   "source": [
    "# Overview \n",
    "This notebook aims to plot U-Pb data in Tera-Wasserburg space and explores discordance metrics and U-Pb uncertainty filtering.\n",
    "\n",
    "### Initial Conditions\n",
    "The code was written using file input as .xlsx file from iolite 4 output, described below, then run through Detrital-Common-Pb-Corrections. The 207Pb-corrected date and uncertainty and Pbc composition are needed (output from Detrital-Common-Pb-Corrections notebook).\n",
    "\n",
    "### Organization\n",
    "The notebook is divided into the following sections: \n",
    "1. [Data import and initial code](#Section1)\n",
    "2. [Plot unfiltered uncorrected U-Pb data](#Section2)\n",
    "3. [Discordance](#Section3)\n",
    "4. [Exploration of data filters](#Section4)\n",
    "5. [Export results](#Section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0a5b5",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "# 1. Import Data and Set-Up\n",
    "\n",
    "## 1.1 Install Python Packages and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726beb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Python packages\n",
    "# Run to see if installed, if not, will install\n",
    "# Only need to install once\n",
    "\n",
    "import importlib\n",
    "from subprocess import run\n",
    "\n",
    "def install_if_not_installed(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"Package {package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing package: {package_name}\")\n",
    "        run(['pip', 'install', package_name], check=True)\n",
    "        print(f\"Installed package: {package_name}\")\n",
    "\n",
    "install_if_not_installed(\"pandas\") # Install pandas\n",
    "install_if_not_installed(\"numpy\") # Install numpy\n",
    "install_if_not_installed(\"matplotlib\") # Install matplotlib\n",
    "install_if_not_installed(\"tabulate\") # Install tabulate\n",
    "install_if_not_installed(\"sympy\") # Install sympy\n",
    "install_if_not_installed(\"easygui\") # Install easygui\n",
    "install_if_not_installed(\"cmcrameri\") # Install cmcrameri\n",
    "install_if_not_installed(\"intersect\") # Install intersect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from cmcrameri import cm\n",
    "from sympy import symbols, Eq, solve, exp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import root\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as mcolors\n",
    "from tabulate import tabulate\n",
    "import easygui\n",
    "from intersect import intersection\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273571a",
   "metadata": {},
   "source": [
    "## 1.2 Input File Organization (Data Needed to Run)\n",
    "Run this section of code to load Excel spreadsheet with U-Pb data. Edit the code to specify the correct file path, file name, and Excel sheet tab.\n",
    "The following sections of code use the following data which must be present in the input file: \n",
    "- Grain ID name\n",
    "- Counts per second: 206, 207, 208\n",
    "- U-Pb ratios and uncertainties (1s or 2s absolute): 206/238, 238/206 and 207/206\n",
    "- Error correlation (rho 207Pb/206Pb v 238U/206Pb)\n",
    "- U/Th ratio\n",
    "- U concentration (ppm)\n",
    "- 207Pb corrected date and uncertainty (from Detrital-Common-Pb-Corrections)\n",
    "- Pbc composition at corrected date (from Detrital-Common-Pb-Corrections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21364a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Excel file with data into DataFrame\n",
    "\n",
    "# Specify the folder and file name\n",
    "folder_path = r'C:\\Users\\megan\\Dropbox\\CommonPbPython\\Example-data'  # Update this with the actual path\n",
    "file_name = 'ExampleData-UPbPlotter-Muelleretal.xlsx'  # Update this with the actual file name\n",
    "sheet_name = 'Sheet1'  # Update this with the actual sheet name\n",
    "\n",
    "# Combine folder path and file name using os.path.join\n",
    "excel_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Load a specific sheet into a DataFrame\n",
    "df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(10) # display first 10 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ca35e",
   "metadata": {},
   "source": [
    "### The following cell defines the input variables used in all subsequent calculations\n",
    "Note that the column headings are displayed in the above cell. Change the below code if the columns are named differently. Code here uses default column headings from iolite 4 export.\n",
    "\n",
    "Prompt asks user to input whether the input uncertainties are 1 or 2 sigma absolute. If 1s (abs), will convert to 2s (abs). The code does not handle uncertainty in percent.\n",
    "\n",
    "*Warning: Code prompts user (bottom), will not continue without an input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define input variables\n",
    "# Everything here will be used in subsequent code\n",
    "# Edit if column names are different than below. See column names in above cell output (or, run df.head(15) )\n",
    "\n",
    "# Define variables by column headers\n",
    "data_dict = df.to_dict(orient='series')\n",
    "\n",
    "# Grain Information\n",
    "GrainID = df['Grain_ID'].copy()\n",
    "\n",
    "# Analytical Information\n",
    "i386 = df['Final U238/Pb206_mean'].copy()\n",
    "i386err = df['Final U238/Pb206_2SE(prop)'].copy() # 2s absolute\n",
    "i76 = df['Final Pb207/Pb206_mean'].copy()\n",
    "i76err = df['Final Pb207/Pb206_2SE(prop)'].copy() # 2s absolute\n",
    "rho = df['rho 207Pb/206Pb v 238U/206Pb'].copy()\n",
    "\n",
    "# Load data from 207Pb correction\n",
    "# here, use 200th iteration, change column header names as needed\n",
    "Date207c = df['207It200_Date207c'].copy() # Load column with final iteration 207Pb-corrected date\n",
    "Date207c_err = df['207It200_Date207cErr'].copy() # Load column with final iteration 207Pb-corrected date uncertainty\n",
    "finalPbc = df['207It200_207/206c'].copy() # 207/206common composition from final iteration\n",
    "\n",
    "Date207c_err_perc = Date207c_err / Date207c * 100\n",
    "df['Date207c_err_perc'] = Date207c_err_perc # Add % err to dataframe\n",
    "\n",
    "\n",
    "user_input = input(\"Are input file uncertainties 1-sigma absolute or 2-sigma absolute? \\nType '1' or '2' (not 'one' or 'two') \\nIf 2, no calculations will be performed \\nIf 1, input uncertainties will be multiplied by 2\\n\")\n",
    "if user_input.lower() == '2':\n",
    "    print(\"\\033[1mInput uncertainties are 2s\\033[0m\")\n",
    "elif user_input == '1':\n",
    "    # Will run the following code if input uncertainties are 1s (abs) and not 2s (abs)\n",
    "    i386err = df['Final U238/Pb206_2SE(prop)'].copy() * 2 # 2s absolute\n",
    "    i76err = df['Final Pb207/Pb206_2SE(prop)'].copy() * 2 # 2s absolute\n",
    "    print('\\033[1mReminder:\\033[0m Input uncertainties are 1s and were multiplied by 2. Subsequent calculations and outputs will be at 2s level')\n",
    "else:\n",
    "    print(\"\\033[1mOops. Invalid input. Please enter '1' or '2'.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8c440",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "# 2. Initial Visualization of Uncorrected U-Pb Data\n",
    "The following cell plots data in Tera-Wasserburg space with 2sigma error ellipses. The code for ellipse plotting is modified from Kurt Sundell AgeCalcML_ConcordiaPlotter.m and from Drew Levy.\n",
    "\n",
    "The cells in Section 2.1 must be run before any code following Section 2.1.\n",
    "\n",
    "*Note that the data plotted are UNcorrected. Common Pb corrections force concordance. The below plots are UNcorrected data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e78b1e",
   "metadata": {},
   "source": [
    "## 2.1 Define concordia and error ellipses\n",
    "\n",
    "The plot_concordia function is used in all subsequent sections to plot the concordia curve. The age increments are set in line: \n",
    "for age in list(range(25, 76, 25)) + list(range(100, 501, 100)) + list(range(1000, 4001, 1000)), where list(min, max, increment) in Ma/Myr.\n",
    "\n",
    "The plot_error_ellipse function is used in all subsequent sections to plot 2s error ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to calculate and plot concordia curve\n",
    "\n",
    "# Define constants\n",
    "instUTh = 1; # instrument-specific U/Th, should be =1 from correction during data reduction\n",
    "rat85 = 137.88; # 238U/235U ratio. 137.88 from Steiger and Jäger (1977). 137.818 from Hiess et al. (2012). \n",
    "rat58 = 0.007252683; # 1/137.88 constant 235/238 U ratio\n",
    "lambda238 = 1.55125E-10; # U238 decay constant from Faure (1986)\n",
    "lambda235 = 9.8485E-10; # U235 decay constant from Faure (1986)\n",
    "lambda232 = 4.9475E-11; # 232Th decay constant\n",
    "\n",
    "def plot_concordia(concordia, lambda238, lambda235, rat85):\n",
    "    # Code for plotting concordia line\n",
    "    # Set up time array\n",
    "    t = np.linspace(1, 6000000000, 1000)  # 1000 points between 1 and 6000000000, time in yrs\n",
    "\n",
    "    # Calculate 206/238 and 207/206 ratios over time\n",
    "    X86 = 1 / (np.exp(lambda238 * t) - 1)  # 206/238 ratio over time\n",
    "    Y76 = (1 / rat85) * (np.exp(lambda235 * t) - 1) / (np.exp(lambda238 * t) - 1)  # 207/206 ratio over time\n",
    "\n",
    "    # Plot the concordia curve\n",
    "    concordia.plot(X86, Y76, color='red', zorder=1)  # Plot concordia\n",
    "\n",
    "    # Label ages at different increments\n",
    "    for age in list(range(25, 76, 25)) + list(range(100, 501, 100)) + list(range(1000, 4001, 1000)):\n",
    "        t = age * 1e6  # Convert age to years\n",
    "        X86 = 1 / (np.exp(lambda238 * t) - 1)\n",
    "        Y76 = (1 / rat85) * (np.exp(lambda235 * t) - 1) / (np.exp(lambda238 * t) - 1)\n",
    "\n",
    "        # Plot red circle at each age increment\n",
    "        concordia.plot(X86, Y76, 'or', markersize=5, zorder=2 + (age - 1) // 25)\n",
    "\n",
    "        # Label each age increment\n",
    "        concordia.text(X86 - 2, Y76 - 0.04, f'{age}', fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to calcualte and plot 2s error ellipses\n",
    "\n",
    "def plot_error_ellipses(ax, i386, i76, i386err, i76err, data_filter = None):\n",
    "    center = np.array([[i386[i], i76[i]] for i in range(len(i386))])\n",
    "    center = np.where(np.all(center == 0, axis=1, keepdims=True), np.nan, center)  # replace 0.0 values with NaN\n",
    "\n",
    "    sigx_abs = i386err\n",
    "    sigy_abs = i76err\n",
    "    percent_error_i386 = np.abs(sigx_abs / i386) * 100\n",
    "    percent_error_i76 = np.abs(sigy_abs / i76) * 100\n",
    "    Date207c_err_perc = Date207c_err / Date207c * 100\n",
    "    PowerLaw = (Date207c ** -0.65) * 8 * 100\n",
    "    rho_values = rho\n",
    "    sigmarule = 1.25\n",
    "    num_ellipse_points = 50\n",
    "\n",
    "    elpt2s_list = []  # Initialize elpt2s outside the loop\n",
    "    ellipses_list = []\n",
    "    uncertainty_filter_list = []\n",
    "    \n",
    "    # set uncertainty_filter to be true/false based on conditions\n",
    "    for i in range(len(center)):\n",
    "        if data_filter == None:\n",
    "            include_condition = True\n",
    "        elif data_filter == \"UPb_Uncertainty\":\n",
    "            if np.isnan(Date207c[i]):\n",
    "                include_condition = False\n",
    "            else:  \n",
    "                include_condition = df_filters['Uncertainty_Filter'][i] == \"include\"\n",
    "        elif data_filter == \"PowerLaw\":\n",
    "            include_condition = df_filters['PowerLaw_Filter'][i] == \"include\"\n",
    "        elif data_filter == \"DateDepend\":\n",
    "            include_condition = df_filters['DateDepend_Filter'][i] == \"include\"\n",
    "        else:\n",
    "            include_condition = False  # Default to False if no valid data_filter is provided\n",
    "\n",
    "        uncertainty_filter_list.append(include_condition)\n",
    "\n",
    "        # Apply the mask\n",
    "        if not include_condition:\n",
    "            continue  # Skip this iteration if the mask is False\n",
    "\n",
    "\n",
    "        # 2 sigma 2D concordia\n",
    "        covmat = np.array([[sigx_abs[i]**2, rho_values[i] * sigx_abs[i] * sigy_abs[i]],\n",
    "                           [rho_values[i] * sigx_abs[i] * sigy_abs[i], sigy_abs[i]**2]])\n",
    "\n",
    "        # Check for NaN or Inf values in covmat\n",
    "        if np.any(np.isnan(covmat)) or np.any(np.isinf(covmat)):\n",
    "            continue  # Skip this iteration due to invalid input data\n",
    "\n",
    "        # Check if covmat is a valid covariance matrix\n",
    "        if not np.all(np.linalg.eigvals(covmat) > 0):\n",
    "            continue  # Skip this iteration due to non-positive eigenvalues\n",
    "\n",
    "        PV, PD = np.linalg.eig(covmat)\n",
    "        theta = np.linspace(0, 2 * np.pi, num_ellipse_points)\n",
    "\n",
    "        elpt2s = np.column_stack((np.cos(theta), np.sin(theta))) @ np.diag(np.sqrt(PV)) @ PD.T\n",
    "        elpt2s = elpt2s * sigmarule + center[i]\n",
    "        elpt2s_list.append(elpt2s)\n",
    "\n",
    "        # Save ellipse parameters in a dictionary\n",
    "        ellipse_params = {\n",
    "            'center': center[i],\n",
    "            'axes': np.sqrt(PV),\n",
    "            'angle': np.degrees(np.arctan2(*PD[:, 0][::-1])),  # Angle in degrees\n",
    "            'points': elpt2s\n",
    "        }\n",
    "\n",
    "        ellipses_list.append(ellipse_params)\n",
    "\n",
    "        ax.plot(elpt2s[:, 0], elpt2s[:, 1], linewidth=0.5, color='black', zorder=7)  # plot error ellipses black outline\n",
    "\n",
    "    all_points = np.concatenate(elpt2s_list)\n",
    "    num_points = np.sum(~np.isnan(center[:, 0]))  # Calculate the number of non-NaN points in the center array\n",
    "\n",
    "    return ellipses_list, all_points, num_points, uncertainty_filter_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25830520",
   "metadata": {},
   "source": [
    "<a id='Section2plot'></a>\n",
    "## 2.2 Plot all uncorrected U-Pb data\n",
    "Plot uncorrected U-Pb data on Tera-Wasserburg diagram. Dimensions of blue box and subplot 2 can be set with x1, y1, x2, y2 below. Run the second cell below to save the figure.\n",
    "\n",
    "This section serves as an initial visualization of all (uncorrected) U-Pb data without any filters. [Section 4](#Section4) explores various filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "### Subplot 1: No Uncertainty threshold applied\n",
    "# Plot concordia and labels\n",
    "concordia = axes[0]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot error ellipses\n",
    "ellipses_list, all_points, num_points, uncertainty_filter_list = plot_error_ellipses(axes[0], i386, i76, i386err, i76err, data_filter = None)\n",
    "error_ellipse_legend = plt.Line2D([0], [0], color='black', linewidth=0.5, alpha=0.5, label='Error ellipses (2s)')\n",
    "\n",
    "# Plot uncorrected U-Pb analyses\n",
    "data_points = axes[0].scatter(i386, i76, color='black', label=f'Analyses (n={num_points}/{num_points})', s=15, zorder=6)\n",
    "\n",
    "\n",
    "\n",
    "### Subplot 2: Zoom In\n",
    "# Plot concordia and labels\n",
    "concordia = axes[1]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot error ellipses\n",
    "ellipses_list, all_points, num_points, uncertainty_filter_list = plot_error_ellipses(axes[1], i386, i76, i386err, i76err)\n",
    "\n",
    "# Plot uncorrected U-Pb analyses\n",
    "data_points = axes[1].scatter(i386, i76, color='black', label=f'Analyses (n={num_points}/{num_points})', s=15, zorder=6)\n",
    "\n",
    "\n",
    "\n",
    "### Plot parameters for both subplots\n",
    "# Set xmin, xmax, ymin, ymax to include all points\n",
    "xmin, xmax = np.min(all_points[:, 0]), np.max(all_points[:, 0])\n",
    "ymin, ymax = np.min(all_points[:, 1]), np.max(all_points[:, 1])\n",
    "axes[0].set_xlim([xmin, xmax])\n",
    "axes[0].set_ylim([ymin, ymax])\n",
    "\n",
    "# Set axis limits for Subplot 2 to zoom on subplot 1, also sets dimensions of blue box\n",
    "x1 = -5\n",
    "x2 = 90\n",
    "y1 = -0.1\n",
    "y2 = 1.2\n",
    "axes[1].set_xlim([x1, x2])\n",
    "axes[1].set_ylim([y1, y2])\n",
    "rectangle = patches.Rectangle((x1, y1), x2, y2, linewidth=1, edgecolor='blue', facecolor='none', zorder=8)\n",
    "axes[0].add_patch(rectangle)\n",
    "axes[0].text(x2, y2+1, 'B', color='blue', fontsize=10, ha='right', va='top', fontweight='bold', zorder=9)\n",
    "\n",
    "# Add labels and legends\n",
    "axes[0].legend(handles=[data_points, error_ellipse_legend])\n",
    "axes[0].set_xlabel(\"$^{238}U/^{206}Pb$\")\n",
    "axes[0].set_ylabel(\"$^{207}Pb/^{206}Pb$\")\n",
    "axes[1].set_xlabel(\"$^{238}U/^{206}Pb$\")\n",
    "axes[1].set_ylabel(\"$^{207}Pb/^{206}Pb$\")\n",
    "\n",
    "axes[0].set_title(\"A. Uncorrected U-Pb results with no filter\")\n",
    "axes[1].set_title(\"B. Uncorrected U-Pb results with no filter\")\n",
    "\n",
    "display(fig)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2151624",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "# Run immediately after generating figure or might save a different figure instead\n",
    "user_input = input(\"Do you want to save the plot? (yes/no): \\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"UncorrectedUPb_nofilter_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52054054",
   "metadata": {},
   "source": [
    "<a id='Section3'></a>\n",
    "# 3. Discordance\n",
    "This section explores various metrics for calculating discordance. Common Pb corrections force concordance, so discordance calculations based on the difference in 206/238 and 207/206 dates are not applicable. This section explores two proposed discordance metrics (see Vermeesch, 2021).\n",
    "\n",
    "#### Stacey-Kramers Distance\n",
    "The Stacey-Kramers distance calculates discordance as the distance between the uncorrected analysis and the corrected analysis (on concordia), following Vermeesch (2021). To do so uses the Pbc composition calculated in the 207Pb correction.\n",
    "\n",
    "The code uses the function 'intersection' from https://github.com/sukhbinder/intersection/tree/master based on the function written for MATLAB https://www.mathworks.com/matlabcentral/fileexchange/11837-fast-and-robust-curve-intersections. \n",
    "\n",
    "\n",
    "#### Aitchison Distance\n",
    "The Aitchison distance calculates the Euclidean distance from the uncorrected analysis to the concordia curve in logarithmic space. The centered log-ratio transformation follows Eqn 4.3 in Pawlowsky-Glahn et al. (2015). See Vermeesch (2021) for further discussion.\n",
    "\n",
    "\n",
    "\n",
    "- Pawlowsky-Glahn, V., Egozcue, J.J., Tolosana-Delgado, R., 2015. Modeling and Analysis of Compositional Data. John Wiley & Sons, Incorporated, Newark, United States.\n",
    "\n",
    "- Vermeesch, P. (2021). On the treatment of discordant detrital zircon U–Pb data. Geochronology, 3(1), 247–257. https://doi.org/10.5194/gchron-3-247-2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d3943",
   "metadata": {},
   "source": [
    "## 3.1 Stacey-Kramers distance\n",
    "This section calculates discordance as the Stacey-Kramers distance. The variables used are the initial 207/206 and 238/206 ratios and 207/206 common composition from the 207Pb correction results (final iteration).\n",
    "\n",
    "The calculation works by defining the line from the analysis to Pbc. Then the intersection function finds the intersection points between the line and concordia curve. The distance between the two intersection points is total_distance, and the distance from the analytical point to the two intersection points defines the concordance and discordance distances. The percent concordant and discordant are calculated from the total distance and lower and upper distances, respectively. Intersection points and distance are not calculated if the slope of the line from the analysis to Pbc is >= 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate discordance using distance from concordia\n",
    "\n",
    "# Define new variables to avoid overwriting\n",
    "Xs386 = i386\n",
    "XsErr = i386err\n",
    "Ys76 = i76\n",
    "YsErr = i76err\n",
    "Pbc = finalPbc # common Pb composition from concatenated 207Pb correction output  \n",
    "\n",
    "# Calculate 206/238 and 207/206 ratios over time\n",
    "t = np.linspace(1, 6000000000, 1000)  # 1000 points between 1 and 6000000000, time in yrs\n",
    "X86 = 1 / (np.exp(lambda238 * t) - 1) # 206/238 ratio over time\n",
    "Y76 = (1 / rat85) * (np.exp(lambda235 * t) - 1) / (np.exp(lambda238 * t) - 1) # 207/206 ratio over time\n",
    "\n",
    "# Set up arrays\n",
    "X1 = np.linspace(0, 10000000)  # change based on the youngest sample lower intercept\n",
    "C = np.zeros((len(Xs386), 10))\n",
    "D3 = np.zeros((len(Xs386), 10))\n",
    "M1 = np.zeros((len(Xs386), 1))\n",
    "\n",
    "# Find intersections of uncorrected analysis with concordia\n",
    "for i in range(len(Xs386)):\n",
    "    c = Pbc[i] # common Pb value is y-intercept\n",
    "    if np.isnan(Xs386[i]) or Xs386[i] == 0: # skip if 238/206 ratio is NaN or 0.0\n",
    "        C = np.array([\"nan\", \"nan\", \"nan\", \"nan\",  \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", c])\n",
    "        D3[i, :] = C\n",
    "    else:\n",
    "        m = (Ys76[i] - c) / Xs386[i]  # define slope of each sample point, y = mx+c\n",
    "        M1[i, :] = m\n",
    "    if m >= 0: # skip if slope >= 0\n",
    "        C = np.array([Xs386[i], XsErr[i], Ys76[i], YsErr[i],  \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", c])\n",
    "        D3[i, :] = C\n",
    "    else:\n",
    "        Y1 = m * X1 + c # define line based on slope and intercept\n",
    "        x, y = intersection(X86, Y76, X1, Y1) # calculate intersection points\n",
    "        # Extract the x and y coordinates of the intersection points; Convert lists to numpy arrays\n",
    "        x_intercept = np.array(x)\n",
    "        y_intercept = np.array(y)\n",
    "\n",
    "        if not intersection:\n",
    "            C = np.array([Xs386[i], XsErr[i], Ys76[i], YsErr[i], \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", c])\n",
    "            D3[i, :] = C\n",
    "        else:\n",
    "            # Calculate age at intercept\n",
    "            t68_1 = np.nan if len(x_intercept) < 1 else np.log((1. / x_intercept[0]) + 1) / lambda238  # 206/238 date in yrs\n",
    "            t68M_1 = np.nan if np.isnan(t68_1) else t68_1 / 1000000  # 206/238 date in Myrs\n",
    "            t68_2 = np.nan if len(x_intercept) < 2 else np.log((1. / x_intercept[1]) + 1) / lambda238  # 206/238 date in yrs\n",
    "            t68M_2 = np.nan if np.isnan(t68_2) else t68_2 / 1000000  # 206/238 date in Myrs\n",
    "\n",
    "            C = np.array([Xs386[i], XsErr[i], Ys76[i], YsErr[i],\n",
    "                          x_intercept[0] if len(x_intercept) > 0 else np.nan,\n",
    "                          y_intercept[0] if len(y_intercept) > 0 else np.nan,\n",
    "                          x_intercept[1] if len(x_intercept) > 1 else np.nan,\n",
    "                          y_intercept[1] if len(y_intercept) > 1 else np.nan,\n",
    "                          m, #t68M_1, t68M_2, \n",
    "                          c])\n",
    "            D3[i, :] = C\n",
    "                \n",
    "\n",
    "# Save results into new DataFrame                \n",
    "df_Discordance = pd.DataFrame(\n",
    "    D3, \n",
    "    columns=[\"238/206measured\", \"238/206m_err\", \"207/206measured\", \"207/206m_err\",\n",
    "           \"Intersect1_X1\", \"Intersect1_Y1\", \"Intersect2_X2\", \"Intersect2_Y2\",\n",
    "           \"Slope (m)\", \"207/206c\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate discordance as distance along discordia\n",
    "df_Discordance['SK_total_distance'] = np.sqrt((df_Discordance['Intersect2_X2'] - df_Discordance['Intersect1_X1'])**2 + (df_Discordance['Intersect2_Y2'] - df_Discordance['Intersect1_Y1'])**2)\n",
    "df_Discordance['SK_upper_distance'] = np.sqrt((df_Discordance['Intersect2_X2'] - df_Discordance['238/206measured'])**2 + (df_Discordance['Intersect2_Y2'] - df_Discordance['207/206measured'])**2)\n",
    "df_Discordance['SK_lower_distance'] = np.sqrt((df_Discordance['238/206measured'] - df_Discordance['Intersect1_X1'])**2 + (df_Discordance['207/206measured'] - df_Discordance['Intersect1_Y1'])**2)\n",
    "df_Discordance['SK_percent_discordant'] = df_Discordance['SK_lower_distance'] / df_Discordance['SK_total_distance'] * 100\n",
    "df_Discordance['SK_percent_concordant'] = df_Discordance['SK_upper_distance'] / df_Discordance['SK_total_distance'] * 100\n",
    "\n",
    "print(df_Discordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb8b09",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize the results\n",
    "Display the results of the Stacey-Kramers discordance calculation. Subplots 1-4 displays all uncorrected U-Pb anayses, intersection points, and intersection lines. Subplots 2-4 color the U-Pb analysis circles by various Stacey-Kramers results values. No data filter is applied. \n",
    "\n",
    "It may take a moment for the plot to populate.\n",
    "\n",
    "Note: adjust the x- and y-axis limits as needed. Adjust vmin and vmax to the desired min/max of colorbar in subplots 2-4, likely close to the x-axis limits of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results of Stacey-Kramers discordance\n",
    "# gray lines and gray points are the intersection lines and points, respectively\n",
    "\n",
    "# uncorrected analysis points\n",
    "num_rows = len(i386)\n",
    "Xs386_data = i386[:num_rows] \n",
    "Ys76_data = i76[:num_rows]\n",
    "percConc = df_Discordance['SK_percent_concordant'][:num_rows]\n",
    "SKdist = df_Discordance['SK_lower_distance'][:num_rows]\n",
    "\n",
    "# intersection points\n",
    "# Extract x, y data for the first 4 rows\n",
    "x1_data = D3[:num_rows, 4] \n",
    "y1_data = D3[:num_rows, 5]\n",
    "x2_data = D3[:num_rows, 6]\n",
    "y2_data = D3[:num_rows, 7]\n",
    "\n",
    "# 207 correction points\n",
    "Pbc_y = Pbc # common Pb composition from concatenated 207Pb correction output \n",
    "Pbc_x = np.full(len(Pbc_y), 0)\n",
    "\n",
    "# Mask analytical points where 238/206 or 207/206 = 0\n",
    "zero_mask = (i386 == 0) | (i76 == 0) | np.isnan(i386) | np.isnan(i76) # number NaN or 0 values\n",
    "\n",
    "print(\"Generating plot. Please be patient...\")\n",
    "plt.close()\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(10, 24))\n",
    "\n",
    "### Subplot 1\n",
    "#Plot concordia and labels\n",
    "concordia = axes[0]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot the points and connect them with lines\n",
    "axes[0].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], color='dimgray', edgecolors='black', linewidths=0.5, \n",
    "                label=f'Uncorrected Analysis n=({np.sum(~zero_mask)})', zorder=3)\n",
    "\n",
    "# Plot intersection lines\n",
    "for i in range(len(x1_data)):\n",
    "    #color = plt.cm.RdPu_r(i / len(x1_data+2))\n",
    "    axes[0].scatter(x1_data[i], y1_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[0].scatter(x2_data[i], y2_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[0].plot([x1_data[i], x2_data[i]], [y1_data[i], y2_data[i]], zorder=1, color='lightgray', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "axes[0].set_xlabel('$^{238}U/^{206}Pb$')\n",
    "axes[0].set_ylabel('$^{207}Pb/^{206}Pb$')\n",
    "axes[0].set_title('Uncorrected U-Pb Data (no filter)')\n",
    "axes[0].set_ylim(-0.1, 1.2)\n",
    "axes[0].set_xlim(-5, 90)\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "### Subplot 2 - colored by Stacey-Kramers distance\n",
    "#Plot concordia and labels\n",
    "concordia = axes[1]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot the points and connect them with lines\n",
    "axes[1].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], color='dimgray', edgecolors='black', linewidths=0.5, \n",
    "                label=f'Analysis without S-K Distance', s=15, zorder=3)\n",
    "scatter_plot = axes[1].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], c=SKdist[~zero_mask], cmap='Purples_r',\n",
    "                               norm=mcolors.LogNorm(vmin=0.1, vmax=1000),\n",
    "                               edgecolors='black', linewidths=0.5,\n",
    "                label=f'Uncorrected Analysis', zorder=4)\n",
    "\n",
    "# Plot intersection lines\n",
    "for i in range(len(x1_data)):\n",
    "    #color = plt.cm.PuRd_r(i / len(x1_data+2))\n",
    "    axes[1].scatter(x1_data[i], y1_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[1].scatter(x2_data[i], y2_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[1].plot([x1_data[i], x2_data[i]], [y1_data[i], y2_data[i]], zorder=1, color='lightgray', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "axes[1].set_xlabel('$^{238}U/^{206}Pb$')\n",
    "axes[1].set_ylabel('$^{207}Pb/^{206}Pb$')\n",
    "axes[1].set_title('Uncorrected U-Pb Data (no filter, colored by % concordant)')\n",
    "axes[1].set_ylim(-0.1, 1.2)\n",
    "axes[1].set_xlim(-5, 90)\n",
    "axes[1].legend()\n",
    "colorbar = plt.colorbar(scatter_plot, ax=axes[1], label='Stacey-Kramers Distance')\n",
    "\n",
    "\n",
    "# Subplot 3 - colored by percent concordant\n",
    "#Plot concordia and labels\n",
    "concordia = axes[2]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot the points and connect them with lines\n",
    "axes[2].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], color='dimgray', edgecolors='black', linewidths=0.5, \n",
    "                label=f'Analysis without S-K Distance', s=15, zorder=3)\n",
    "scatter_plot = axes[2].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], c=percConc[~zero_mask], cmap='YlGn_r', \n",
    "                vmin=0, vmax=100, edgecolors='black', linewidths=0.5,\n",
    "                label=f'Uncorrected Analysis', zorder=4)\n",
    "\n",
    "# Plot intersection lines\n",
    "for i in range(len(x1_data)):\n",
    "    axes[2].scatter(x1_data[i], y1_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[2].scatter(x2_data[i], y2_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[2].plot([x1_data[i], x2_data[i]], [y1_data[i], y2_data[i]], zorder=1, color='lightgray', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "axes[2].set_xlabel('$^{238}U/^{206}Pb$')\n",
    "axes[2].set_ylabel('$^{207}Pb/^{206}Pb$')\n",
    "axes[2].set_title('Uncorrected U-Pb Data (no filter, colored by % concordant)')\n",
    "axes[2].set_ylim(-0.1, 1.2)\n",
    "axes[2].set_xlim(-5, 90)\n",
    "axes[2].legend()\n",
    "colorbar = plt.colorbar(scatter_plot, ax=axes[2], label='Concordance (%)')\n",
    "\n",
    "\n",
    "\n",
    "# Subplot 4 - colored by lower intersection\n",
    "#Plot concordia and labels\n",
    "concordia = axes[3]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot the points and connect them with lines\n",
    "axes[3].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], color='dimgray', edgecolors='black', linewidths=0.5, \n",
    "                label=f'Analysis without S-K Distance', s=15, zorder=3)\n",
    "scatter_plot = axes[3].scatter(Xs386_data[~zero_mask], Ys76_data[~zero_mask], c=x1_data[~zero_mask], cmap='Blues_r', \n",
    "                vmin=0, vmax=100, edgecolors='black', linewidths=0.5, \n",
    "                label=f'Uncorrected Analysis (n={np.count_nonzero(~zero_mask)}/{np.sum(~zero_mask)})', zorder=3)\n",
    "\n",
    "# Plot intersection lines\n",
    "for i in range(len(x1_data)):\n",
    "    axes[3].scatter(x1_data[i], y1_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[3].scatter(x2_data[i], y2_data[i], s=15, color='lightgray', edgecolors='black', linewidths=0.5, zorder=2)\n",
    "    axes[3].plot([x1_data[i], x2_data[i]], [y1_data[i], y2_data[i]], zorder=1, color='lightgray', alpha=0.5)\n",
    "\n",
    "\n",
    "axes[3].set_xlabel('$^{238}U/^{206}Pb$')\n",
    "axes[3].set_ylabel('$^{207}Pb/^{206}Pb$')\n",
    "axes[3].set_title('Uncorrected U-Pb Data (no filter, colored by lower intersection)')\n",
    "axes[3].set_ylim(-0.1, 1.2)\n",
    "axes[3].set_xlim(-5, 90)\n",
    "axes[3].legend()\n",
    "colorbar = plt.colorbar(scatter_plot, ax=axes[3], label='Lower Intersection (in $^{238}U/^{206}Pb$)')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "# Run immediately after generating figure or might save a different figure instead\n",
    "user_input = input(\"Do you want to save the plot? (yes/no): \\n yes/no is case sensitive \\n If yes, will open window to save \\n Please be patient as figure saves... \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"Discordance_SKdistance_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3e843",
   "metadata": {},
   "source": [
    "## 3.2 Aitchison distance\n",
    "Calculate the Aitchison distance then plot the results.\n",
    "\n",
    "Centered log-ratio transformation (see Eqn 4.3 in Pawlowsky-Glahn et al., 2015):\n",
    "1. Create a vector representing the geometric mean for each row of the compositional data: np.geomspace(1, 1, UPb_data.shape[1])\n",
    "2. Normalize data by element-wise division of each row in UPb_data by the corresponding geometric mean\n",
    "3. Take natural log of ratios\n",
    "4. Resulting log_ratio_UPb_data array contains the log-ratio-transformed compositional data\n",
    "\n",
    "- Pawlowsky-Glahn, V., Egozcue, J.J., Tolosana-Delgado, R., 2015. Modeling and Analysis of Compositional Data. John Wiley & Sons, Incorporated, Newark, United States.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Aitchison distance\n",
    "\n",
    "# Initial variables\n",
    "Xs386 = i386\n",
    "XsErr = i386err\n",
    "Ys76 = i76\n",
    "YsErr = i76err\n",
    "\n",
    "# Set up concordia curve time array\n",
    "t = np.linspace(1, 6000e6, 1000)  # 1000 points between 1 and 6000000000, time in yrs\n",
    "X86 = 1 / (np.exp(lambda238 * t) - 1) # 206/238 ratio over time\n",
    "Y76 = (1 / rat85) * (np.exp(lambda235 * t) - 1) / (np.exp(lambda238 * t) - 1) # 207/206 ratio over time\n",
    "\n",
    "# Mark some points along the concordia at specified times\n",
    "tMyr = np.array([75e6, 100e6, 200e6, 350e6, 500e6, 750e6, 1000e6, 2000e6, 3000e6, 4000e6])\n",
    "X86tMyr = 1 / (np.exp(lambda238 * tMyr) - 1) # 206/238 ratio at specified time\n",
    "Y76tMyr = (1 / rat85) * (np.exp(lambda235 * tMyr) - 1) / (np.exp(lambda238 * tMyr) - 1) # 207/206 ratio at specified time\n",
    "age = tMyr / 1e6\n",
    "\n",
    "# U-Pb data and concordia curve\n",
    "UPb_data = np.column_stack((Xs386, Ys76))\n",
    "curve_data = np.column_stack((X86, Y76))\n",
    "\n",
    "# Replace negative or 0.0 values with NaN\n",
    "UPb_data = np.where((UPb_data == 0.0) | (UPb_data < 0.0), np.nan, UPb_data)\n",
    "curve_data = np.where((curve_data == 0.0) | (curve_data < 0.0), np.nan, curve_data)\n",
    "\n",
    "# Centered log-ratio transformation\n",
    "log_ratio_UPb_data = np.log(UPb_data / np.geomspace(1, 1, UPb_data.shape[1]))\n",
    "log_ratio_curve_data = np.log(curve_data / np.geomspace(1, 1, curve_data.shape[1]))\n",
    "\n",
    "# Calculate Aitchison distances\n",
    "aitchison_distances = cdist(log_ratio_UPb_data, log_ratio_curve_data, metric='euclidean')\n",
    "\n",
    "# Find the minimum distances\n",
    "aitchison_distances_min = np.min(aitchison_distances, axis=1)\n",
    "df_Discordance['Aitchison_distance'] = aitchison_distances_min\n",
    "\n",
    "# Print the results\n",
    "print(\"Aitchison Distances (Distance from U-Pb analysis to every pt of concordia curve, 1000 distances per analysis):\")\n",
    "print(aitchison_distances[:5])\n",
    "\n",
    "print(\"\\n\\nMinimum Aitchison Distance:\")\n",
    "print(aitchison_distances_min[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c422a",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "Display the results of the Aitchison distance discordance calculation. All points are uncorrected U-Pb analyses. The U-Pb analyses are colored by Aitchison distance in both plots. No filter is applied to the U-Pb data.\n",
    "\n",
    "Note: This section does not use the concordia function. Update 'tMyr' to determine which ages are labeled on concordia curve. Modify 't_isochron' variable to set the date of the isochron plotted on both subplots.Adjust 't_isochron' to change which isochron date is plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Aitchison distance\n",
    "\n",
    "\n",
    "# calculate discordia line at 185 Ma\n",
    "t_isochron = 185e6 # date in yrs\n",
    "X2_line = 1 / (np.exp(lambda238 * t_isochron) - 1)\n",
    "Y2_line = (1 / rat85) * (np.exp(lambda235 * t_isochron) - 1) / (np.exp(lambda238 * t_isochron) - 1)\n",
    "X1_line = 1e-10\n",
    "a64 = 9.74 * (np.exp((lambda238 * 3.7E9)) - np.exp((lambda238 * t_isochron))) + 11.152 # 206/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "a74 = (9.74 / rat85) * (np.exp((lambda235 * 3.7E9)) - np.exp((lambda235 * t_isochron))) + 12.998 # 207/204 common ratio from estimated dates younger than 3.7 Ga using Stacey-Kramers eqn. and initial 206/238 Age estimate\n",
    "Y1_line = a74 / a64\n",
    "slope = (Y2_line - Y1_line) / (X2_line - X1_line)\n",
    "b = Y1_line - slope * X1_line\n",
    "x_values = np.linspace(-10, 100, 100)\n",
    "y_values = slope * x_values + b\n",
    "\n",
    "# Avoid zero or negative y_values by clipping to a small positive value\n",
    "x_values_clip = np.clip(x_values, a_min=1e-6, a_max=None)\n",
    "y_values_clip = np.clip(y_values, a_min=1e-6, a_max=None)  \n",
    "ln_x_values = np.log(x_values_clip)\n",
    "ln_y_values = np.log(y_values_clip)\n",
    "\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.close()\n",
    "plt.figure(figsize=(12,6))\n",
    "cmap = cm.davos_r # set colormap\n",
    "\n",
    "### Subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.log(X86), np.log(Y76), label='Concordia', color='red')\n",
    "plt.scatter(np.log(X86tMyr), np.log(Y76tMyr), color='red', s=10)  # Mark specified points in red\n",
    "plt.plot(ln_x_values, ln_y_values, label='185 Ma isochron', color='black') # label=f'ln(y) = {slope:.2f}ln(x) + {np.log(np.abs(b)):.2f}'\n",
    "scatter2 = plt.scatter(np.log(Xs386), np.log(Ys76), c=aitchison_distances_min, cmap=cmap, label='Analyses',  edgecolors='black', linewidth=0.5)  # Scatter plot of data in black\n",
    "\n",
    "plt.xlim(-2,5) # adjust as needed\n",
    "plt.ylim(-3.2, 2.1) # adjust as needed\n",
    "plt.xlabel(r'$\\ln\\left({^{238}U}/{^{206}Pb}\\right)$')\n",
    "plt.ylabel(r'$\\ln\\left({^{207}Pb}/{^{206}Pb}\\right)$')\n",
    "plt.title('A. Tera-Wasserburg Diagram in ln-ln Space')\n",
    "#plt.legend()\n",
    "cbar = plt.colorbar(scatter2, label='Perpendicular Aitchison Distance')\n",
    "\n",
    "# Add text labels for specified points on concordia\n",
    "for i, age in enumerate(tMyr / 1e6):\n",
    "    plt.text(np.log(X86tMyr[i])-0.04, np.log(Y76tMyr[i]) -0.07, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "\n",
    "### Subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(X86, Y76, label='Concordia', color='red')\n",
    "plt.scatter(X86tMyr, Y76tMyr, color='red', s=10)  # Mark specified points in red\n",
    "plt.plot(x_values, y_values, label='185 Ma isochron', color='black') # label = f'y = {slope:.2f}x + {b:.2f}'\n",
    "scatter1 = plt.scatter(Xs386, Ys76, c=aitchison_distances_min, cmap=cmap, label='Analyses (no filters)', \n",
    "                       edgecolors='black', linewidth=0.5)\n",
    "plt.xlabel('$^{238}U/^{206}Pb$')\n",
    "plt.ylabel('$^{207}Pb/^{206}Pb$')\n",
    "plt.title('B. Tera-Wasserburg Diagram of Uncorrected U-Pb Data')\n",
    "plt.xlim(-7, 90) # adjust as needed\n",
    "plt.ylim(0, 2) # adjust as needed\n",
    "plt.legend()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter1, label='Perpendicular Aitchison Distance')\n",
    "\n",
    "# Add text labels for specified points on concordia\n",
    "for i, age in enumerate(tMyr / 1e6):\n",
    "    plt.text(X86tMyr[i] -1, Y76tMyr[i] -0.05, f'{age:.0f}', fontsize=8, color='black', ha='right', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe446fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "# Run immediately after generating figure or might save a different figure instead\n",
    "user_input = input(\"Do you want to save the plot? (yes/no): \\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"Discordance_AitchisonDistance_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        plt.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2d37c",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "# 4. Explore U-Pb Filters\n",
    "\n",
    "The following section includes Tera-Wasserburg diagrams of uncorrected U-Pb data to explore various filters. All data points (unfiltered) are plotted in [Section 2](#Section2plot).\n",
    "\n",
    "#### Explore effects of filtering by applying an uncertainty threshold:\n",
    "- Only points < 20% uncertainty on 238/206 *and* 207/206 ratios (modified from Lippert, 2014)\n",
    "- Date-dependent uncertainty windows (following Govin et al., 2018, Geology)\n",
    "    * 207Pb-corrected date > 100 Ma, uncertainty > 10 %\n",
    "    * 207Pb-corrected date 10-100 Ma, uncertainty > 20 %\n",
    "    * 207Pb-corrected date < 10 Ma, uncertainty > 25 %\n",
    "- Power law uncertainty filter (following Chew et al., 2020, Earth Sci. Rev.)\n",
    "    * 207Pb corrected date uncertainty (2s %) =  8 x (date ^ -0.65)\n",
    "\n",
    "\n",
    "Note that the U-Pb data plotted are UNcorrected. Common Pb corrections force concordance. The below plots are UNcorrected data. Adjust axis limits as needed.\n",
    "\n",
    "- Chew, D., O’Sullivan, G., Caracciolo, L., Mark, C., Tyrrell, S., 2020. Sourcing the sand: Accessory mineral fertility, analytical and other biases in detrital U-Pb provenance analysis. Earth-Science Reviews 202, 103093. https://doi.org/10.1016/j.earscirev.2020.103093\n",
    "\n",
    "- Govin, G., Najman, Y., Copley, A., Millar, I., van der Beek, P., Huyghe, P., Grujic, D., Davenport, J., 2018. Timing and mechanism of the rise of the Shillong Plateau in the Himalayan foreland. Geology 46, 279–282. https://doi.org/10.1130/G39864.1\n",
    "\n",
    "- Lippert, P.G., 2014. Detrital U-Pb geochronology provenance analyses: case studies in the Greater Green River Basin, Wyoming, and the Book Cliffs, Utah (Thesis). University of Kansas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define which analyses to include/exclude based on filters\n",
    "\n",
    "# Variables\n",
    "Xs386 = i386\n",
    "XsErr = i386err\n",
    "Ys76 = i76\n",
    "YsErr = i76err\n",
    "XsErrPerc = abs(XsErr / Xs386 * 100) # use absolute values to exclude negatives\n",
    "YsErrPerc = abs(YsErr / Ys76 * 100)\n",
    "\n",
    "power_law = (Date207c ** -0.65) * 8 * 100\n",
    "\n",
    "# Create a condition based on the variables\n",
    "threshold = 20 # threshold to use for U-Pb ratio uncertainty (i.e., 20%)\n",
    "UPb_PercErr_filter = np.where((XsErrPerc < threshold) & (YsErrPerc < threshold), 'include', 'exclude')\n",
    "\n",
    "power_law_filter = np.where((Date207c_err_perc < power_law), 'include', 'exclude')\n",
    "\n",
    "# Add to new dataframe\n",
    "df_filters = pd.DataFrame({'238/206_Err(%)': XsErrPerc, '207/206_Err(%)': YsErrPerc, 'Uncertainty_Filter': UPb_PercErr_filter, 'PowerLaw_Filter': power_law_filter})\n",
    "\n",
    "# Date-dependent filter conditions\n",
    "condition_1 = (Date207c_err_perc > 10) & (Date207c > 100)\n",
    "condition_2 = ((Date207c_err_perc > 20) & (Date207c > 10) & (Date207c <= 100))\n",
    "condition_3 = (Date207c_err_perc > 25) & (Date207c <= 10)\n",
    "condition_4 = (Date207c == 0.0) | pd.isnull(Date207c)\n",
    "\n",
    "# Add to dataframe\n",
    "df_filters['DateDepend_Filter'] = np.where(condition_1 | condition_2 | condition_3 | condition_4, 'exclude', 'include')\n",
    "\n",
    "# Print the result DataFrame\n",
    "print(df_filters.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "print(\"Generating plot. Please be patient...\")\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 12)) # figsize(width,height)\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25) # adjust spacing between subplots\n",
    "\n",
    "\n",
    "### Subplot 1: Only points < 20% uncertainty on 207/206 and 238/206 ratios (set uncertainty threshold % in cell above; modified from Lippert, 2014)\n",
    "\n",
    "# Plot concordia and labels\n",
    "concordia = axes[0]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot error ellipses\n",
    "ellipses_list, all_points, num_points, uncertainty_filter_list = plot_error_ellipses(axes[0], i386, i76, i386err, i76err, \n",
    "                                                                                 data_filter = 'UPb_Uncertainty')\n",
    "error_ellipse_legend = plt.Line2D([0], [0], color='black', linewidth=0.5, alpha=0.5, label='Error ellipses (2s)')\n",
    "\n",
    "# Plot uncorrected U-Pb analyses\n",
    "uncertainty_filter = np.array(uncertainty_filter_list)\n",
    "num_analyses_included = np.count_nonzero(uncertainty_filter)\n",
    "data_points = axes[0].scatter(i386[uncertainty_filter], i76[uncertainty_filter], color='black', \n",
    "                              label=f'Analyses (n={num_analyses_included}/{num_points})', s=5, zorder=6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Subplot 2: Following date-dependent filter on age uncertainty from Govin et al., 2018\n",
    "\n",
    "# Plot concordia and labels\n",
    "concordia = axes[1]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot error ellipses\n",
    "ellipses_list, all_points, num_points, uncertainty_filter_list = plot_error_ellipses(axes[1], i386, i76, i386err, i76err, \n",
    "                                                                                     data_filter = 'DateDepend')\n",
    "error_ellipse_legend = plt.Line2D([0], [0], color='black', linewidth=0.5, alpha=0.5, label='Error ellipses (2s)')\n",
    "\n",
    "# Plot uncorrected U-Pb analyses\n",
    "uncertainty_filter = np.array(uncertainty_filter_list)\n",
    "num_analyses_included = np.count_nonzero(uncertainty_filter)\n",
    "data_points = axes[1].scatter(i386[uncertainty_filter], i76[uncertainty_filter], color='black', \n",
    "                              label=f'Analyses (n={num_analyses_included}/{num_points})', s=5, zorder=6)\n",
    "\n",
    "\n",
    "\n",
    "### Subplot 3: Following power law filter on age uncertainty from Chew et al., 2020\n",
    "\n",
    "# Plot concordia and labels\n",
    "concordia = axes[2]\n",
    "plot_concordia(concordia, lambda238, lambda235, rat85)\n",
    "\n",
    "# Plot error ellipses\n",
    "ellipses_list, all_points, num_points, uncertainty_filter_list = plot_error_ellipses(axes[2], i386, i76, i386err, i76err, \n",
    "                                                                                     data_filter = \"PowerLaw\")\n",
    "error_ellipse_legend = plt.Line2D([0], [0], color='black', linewidth=0.5, alpha=0.5, label='Error ellipses (2s)')\n",
    "\n",
    "# Plot uncorrected U-Pb analyses\n",
    "uncertainty_filter = np.array(uncertainty_filter_list)\n",
    "num_analyses_included = np.count_nonzero(uncertainty_filter)\n",
    "data_points = axes[2].scatter(i386[uncertainty_filter], i76[uncertainty_filter], color='black', \n",
    "                              label=f'Analyses (n={num_analyses_included}/{num_points})', s=5, zorder=6)\n",
    "\n",
    "# Add included/excluded to DataFrame\n",
    "# Change header as needed\n",
    "df['PowerLaw (Chew2020)'] = np.where(uncertainty_filter, 'include', 'exclude')\n",
    "\n",
    "\n",
    "## Plot parameters for all subplots\n",
    "\n",
    "# Set axis limits for Subplot 2 to zoom on subplot 1, also sets dimensions of blue box\n",
    "# caluclate min, max to include all points\n",
    "xmin, xmax = np.min(all_points[:, 0]), np.max(all_points[:, 0])\n",
    "ymin, ymax = np.min(all_points[:, 1]), np.max(all_points[:, 1])\n",
    "\n",
    "# set axis limits for all subplots\n",
    "# can use xmin, xmax, ymin, ymax or manually-set values\n",
    "axes[0].set_xlim([xmin, xmax])\n",
    "axes[0].set_ylim([ymin, ymax])\n",
    "axes[0].set_xlim([-5, 90])\n",
    "axes[0].set_ylim([-0.1, 1.2])\n",
    "#axes[1].set_xlim([xmin,xmax])\n",
    "#axes[1].set_ylim([ymin, ymax])\n",
    "axes[1].set_xlim([-5, 90])\n",
    "axes[1].set_ylim([-0.1, 1.2])\n",
    "#axes[0].set_xlim([xmin, xmax])\n",
    "#axes[0].set_ylim([ymin, ymax])\n",
    "axes[0].set_xlim([-5, 90])\n",
    "axes[0].set_ylim([-0.1, 1.2])\n",
    "axes[1].set_xlim([-5, 90])\n",
    "axes[1].set_ylim([-0.1, 1.2])\n",
    "axes[2].set_xlim([-5, 90])\n",
    "axes[2].set_ylim([-0.1, 1.2])\n",
    "\n",
    "\n",
    "# Add labels and legends\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "axes[2].legend()\n",
    "\n",
    "axes[0].set_xlabel(\"$^{238}U/^{206}Pb$\")\n",
    "axes[0].set_ylabel(\"$^{207}Pb/^{206}Pb$\")\n",
    "axes[1].set_xlabel(\"$^{238}U/^{206}Pb$\")\n",
    "axes[1].set_ylabel(\"$^{207}Pb/^{206}Pb$\")\n",
    "axes[2].set_xlabel(\"$^{238}U/^{206}Pb$\")\n",
    "axes[2].set_ylabel(\"$^{207}Pb/^{206}Pb$\")\n",
    "\n",
    "axes[0].set_title(f\"A. Uncorrected U-Pb results with 238/206 and 207/206 uncertainty filter ({threshold}%)\")\n",
    "axes[1].set_title(\"B. Uncorrected U-Pb results with 207Pbc date-dependent filter (Govin et al 2018)\")\n",
    "axes[2].set_title(\"C. Uncorrected U-Pb results with power law filter (Chew et al 2020)\")\n",
    "\n",
    "display(fig)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to save figure\n",
    "# Run immediately after generating figure or might save a different figure instead\n",
    "user_input = input(\"Do you want to save the plot? (yes/no): \\n yes/no is case sensitive \\n If yes, will open window to save \\n Please be patient as figure saves... \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"UPb_UncertaintyFilters_v1.pdf\"),\n",
    "        filetypes=[\"*.pdf\"],\n",
    "        title=\"Select Folder and File Name to Save PDF File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the figure\n",
    "    if file_path:\n",
    "        fig.savefig(file_path, format=\"pdf\")\n",
    "        print(\"\\033[1mFigure saved successfully at:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mFigure not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mFigure not saved.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb0edc",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "# 5. View and Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to concatenate DataFrames horizontally\n",
    "result_df = pd.concat([df, df_Discordance, df_filters], axis=1)\n",
    "\n",
    "# Display the result\n",
    "result_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb110afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export the DataFrame to Excel\n",
    "# do not run without running above cell to concatenate dataframes\n",
    "\n",
    "user_input = input(\"Do you want to save to Excel? (yes/no): \\n yes/no is case sensitive \\n If yes, will open window to save \\n\")\n",
    "\n",
    "if user_input.lower() == 'yes':\n",
    "    # Ask the user for the folder and filename to save the file\n",
    "    file_path = easygui.filesavebox(\n",
    "        default=os.path.join(folder_path, \"OutputFile_UPbPlotter_v1.xlsx\"),\n",
    "        filetypes=[\"*.xlsx\"],\n",
    "        title=\"Select Folder and File Name to Save Excel File\"\n",
    "    )\n",
    "\n",
    "    # If the user selected a file path, save the DataFrame to Excel\n",
    "    if file_path:\n",
    "        result_df.to_excel(file_path, index=False)\n",
    "        print(\"\\033[1mDataFrame saved to Excel:\\033[0m\", file_path)\n",
    "    else:\n",
    "        print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[1mDataFrame not saved.\\033[0m\")\n",
    "\n",
    "\n",
    "# Display the concatenated DataFrame \n",
    "#pd.set_option('display.max_columns', None)\n",
    "#print('\\n\\n\\033[1mConcatenated DataFrame:')\n",
    "#result_df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
